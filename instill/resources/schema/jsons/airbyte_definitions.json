{ "$schema": "http://json-schema.org/draft-07/schema#", "oneOf": [ { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "access_key": { "instillCredentialField": true, "description": "The Access Key ID of the AWS IAM Role to use for sending messages", "examples": [ "xxxxxHRNxxx3TBxxxxxx" ], "order": 3, "title": "AWS IAM Access Key ID", "type": "string" }, "destination": { "const": "airbyte-destination-amazon-sqs", "type": "string" }, "message_body_key": { "description": "Use this property to extract the contents of the named key in the input record to use as the SQS message body. If not set, the entire content of the input record data is used as the message body.", "examples": [ "myDataPath" ], "order": 5, "title": "Message Body Key", "type": "string" }, "message_delay": { "description": "Modify the Message Delay of the individual message from the Queue's default (seconds).", "examples": [ "15" ], "order": 2, "title": "Message Delay", "type": "integer" }, "message_group_id": { "description": "The tag that specifies that a message belongs to a specific message group. This parameter applies only to, and is REQUIRED by, FIFO queues.", "examples": [ "my-fifo-group" ], "order": 6, "title": "Message Group Id", "type": "string" }, "queue_url": { "description": "URL of the SQS Queue", "examples": [ "https://sqs.eu-west-1.amazonaws.com/1234567890/my-example-queue" ], "order": 0, "title": "Queue URL", "type": "string" }, "region": { "description": "AWS Region of the SQS Queue", "enum": [ "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 1, "title": "AWS Region", "type": "string" }, "secret_key": { "instillCredentialField": true, "description": "The Secret Key of the AWS IAM Role to use for sending messages", "examples": [ "hu+qE5exxxxT6o/ZrKsxxxxxxBhxxXLexxxxxVKz" ], "order": 4, "title": "AWS IAM Secret Key", "type": "string" } }, "required": [ "queue_url", "region", "destination" ], "title": "Amazonsqs", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "aws_account_id": { "description": "target aws account id", "examples": [ "111111111111" ], "order": 1, "title": "AWS Account Id", "type": "string" }, "bucket_name": { "description": "The name of the S3 bucket. Read more <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html\">here</a>.", "order": 4, "title": "S3 Bucket Name", "type": "string" }, "bucket_prefix": { "description": "S3 prefix", "order": 5, "title": "Target S3 Bucket Prefix", "type": "string" }, "credentials": { "description": "Choose How to Authenticate to AWS.", "oneOf": [ { "properties": { "credentials_title": { "const": "IAM Role", "default": "IAM Role", "description": "Name of the credentials", "enum": [ "IAM Role" ], "order": 0, "title": "Credentials Title", "type": "string" }, "role_arn": { "instillCredentialField": false, "description": "Will assume this role to write data to s3", "title": "Target Role Arn", "type": "string" } }, "required": [ "role_arn", "credentials_title" ], "title": "IAM Role", "type": "object" }, { "properties": { "aws_access_key_id": { "instillCredentialField": true, "description": "AWS User Access Key Id", "title": "Access Key Id", "type": "string" }, "aws_secret_access_key": { "instillCredentialField": true, "description": "Secret Access Key", "title": "Secret Access Key", "type": "string" }, "credentials_title": { "const": "IAM User", "default": "IAM User", "description": "Name of the credentials", "enum": [ "IAM User" ], "order": 0, "title": "Credentials Title", "type": "string" } }, "required": [ "credentials_title", "aws_access_key_id", "aws_secret_access_key" ], "title": "IAM User", "type": "object" } ], "order": 2, "title": "Authentication mode", "type": "object" }, "destination": { "const": "airbyte-destination-aws-datalake", "type": "string" }, "format": { "description": "Format of the data output.", "oneOf": [ { "properties": { "compression_codec": { "default": "UNCOMPRESSED", "description": "The compression algorithm used to compress data.", "enum": [ "UNCOMPRESSED", "GZIP" ], "title": "Compression Codec (Optional)", "type": "string" }, "format_type": { "default": "JSONL", "enum": [ "JSONL" ], "title": "Format Type *", "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: Newline-delimited JSON" }, { "properties": { "compression_codec": { "default": "SNAPPY", "description": "The compression algorithm used to compress data.", "enum": [ "UNCOMPRESSED", "SNAPPY", "GZIP", "ZSTD" ], "title": "Compression Codec (Optional)", "type": "string" }, "format_type": { "default": "Parquet", "enum": [ "Parquet" ], "title": "Format Type *", "type": "string" } }, "required": [ "format_type" ], "title": "Parquet: Columnar Storage" } ], "order": 10, "title": "Output Format *", "type": "object" }, "glue_catalog_float_as_decimal": { "default": false, "description": "Cast float/double as decimal(38,18). This can help achieve higher accuracy and represent numbers correctly as received from the source.", "order": 12, "title": "Glue Catalog: Float as Decimal", "type": "boolean" }, "lakeformation_database_default_tag_key": { "description": "Add a default tag key to databases created by this destination", "examples": [ "pii_level" ], "order": 7, "title": "Lake Formation Database Tag Key", "type": "string" }, "lakeformation_database_default_tag_values": { "description": "Add default values for the `Tag Key` to databases created by this destination. Comma separate for multiple values.", "examples": [ "private,public" ], "order": 8, "title": "Lake Formation Database Tag Values", "type": "string" }, "lakeformation_database_name": { "description": "The default database this destination will use to create tables in per stream. Can be changed per connection by customizing the namespace.", "order": 6, "title": "Lake Formation Database Name", "type": "string" }, "lakeformation_governed_tables": { "default": false, "description": "Whether to create tables as LF governed tables.", "order": 9, "title": "Lake Formation Governed Tables", "type": "boolean" }, "partitioning": { "default": "NO PARTITIONING", "description": "Partition data by cursor fields when a cursor field is a date", "enum": [ "NO PARTITIONING", "DATE", "YEAR", "MONTH", "DAY", "YEAR/MONTH", "YEAR/MONTH/DAY" ], "order": 11, "title": "Choose how to partition data", "type": "string" }, "region": { "default": "", "description": "The region of the S3 bucket. See <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions\">here</a> for all region codes.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 3, "title": "S3 Bucket Region", "type": "string" } }, "required": [ "credentials", "region", "bucket_name", "lakeformation_database_name", "destination" ], "title": "Awsdatalake", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "azure_blob_storage_account_key": { "instillCredentialField": true, "description": "The Azure blob storage account key.", "examples": [ "Z8ZkZpteggFx394vm+PJHnGTvdRncaYS+JhLKdj789YNmD+iyGTnG+PV+POiuYNhBg/ACS+LKjd%4FG3FHGN12Nd==" ], "title": "Azure Blob Storage account key", "type": "string" }, "azure_blob_storage_account_name": { "description": "The account's name of the Azure Blob Storage.", "examples": [ "airbyte5storage" ], "title": "Azure Blob Storage account name", "type": "string" }, "azure_blob_storage_container_name": { "description": "The name of the Azure blob storage container. If not exists - will be created automatically. May be empty, then will be created automatically airbytecontainer+timestamp", "examples": [ "airbytetescontainername" ], "title": "Azure blob storage container (Bucket) Name", "type": "string" }, "azure_blob_storage_endpoint_domain_name": { "default": "blob.core.windows.net", "description": "This is Azure Blob Storage endpoint domain name. Leave default value (or leave it empty if run container from command line) to use Microsoft native from example.", "examples": [ "blob.core.windows.net" ], "title": "Endpoint Domain Name", "type": "string" }, "azure_blob_storage_output_buffer_size": { "default": 5, "description": "The amount of megabytes to buffer for the output stream to Azure. This will impact memory footprint on workers, but may need adjustment for performance and appropriate block size in Azure.", "examples": [ 5 ], "maximum": 2047, "minimum": 1, "title": "Azure Blob Storage output buffer size (Megabytes)", "type": "integer" }, "azure_blob_storage_spill_size": { "default": 500, "description": "The amount of megabytes after which the connector should spill the records in a new blob object. Make sure to configure size greater than individual records. Enter 0 if not applicable", "examples": [ 500 ], "title": "Azure Blob Storage file spill size", "type": "integer" }, "destination": { "const": "airbyte-destination-azure-blob-storage", "type": "string" }, "format": { "description": "Output data format", "oneOf": [ { "properties": { "flattening": { "default": "No flattening", "description": "Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Normalization (Flattening)", "type": "string" }, "format_type": { "const": "CSV", "type": "string" } }, "required": [ "format_type", "flattening" ], "title": "CSV: Comma-Separated Values" }, { "properties": { "format_type": { "const": "JSONL", "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: newline-delimited JSON" } ], "title": "Output Format", "type": "object" } }, "required": [ "azure_blob_storage_account_name", "azure_blob_storage_account_key", "format", "destination" ], "title": "Azureblobstorage", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "groups": [ { "id": "connection", "title": "Connection" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "big_query_client_buffer_size_mb": { "default": 15, "description": "Google BigQuery client's chunk (buffer) size (MIN=1, MAX = 15) for each table. The size that will be written by a single RPC. Written data will be buffered and only flushed upon reaching this size or closing the channel. The default 15MB value is used if not set explicitly. Read more <a href=\"https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html\">here</a>.", "examples": [ "15" ], "group": "advanced", "maximum": 15, "minimum": 1, "order": 6, "title": "Google BigQuery Client Chunk Size", "type": "integer" }, "credentials_json": { "instillCredentialField": true, "always_show": true, "description": "The contents of the JSON service account key. Check out the <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#service-account-key\">docs</a> if you need help generating this key. Default credentials will be used if this field is left empty.", "group": "connection", "order": 4, "title": "Service Account Key JSON (Required for cloud, optional for open-source)", "type": "string" }, "dataset_id": { "description": "The default BigQuery Dataset ID that tables are replicated to if the source does not specify a namespace. Read more <a href=\"https://cloud.google.com/bigquery/docs/datasets#create-dataset\">here</a>.", "group": "connection", "order": 2, "title": "Default Dataset ID", "type": "string" }, "dataset_location": { "description": "The location of the dataset. Warning: Changes made after creation will not be applied. Read more <a href=\"https://cloud.google.com/bigquery/docs/locations\">here</a>.", "enum": [ "US", "EU", "asia-east1", "asia-east2", "asia-northeast1", "asia-northeast2", "asia-northeast3", "asia-south1", "asia-south2", "asia-southeast1", "asia-southeast2", "australia-southeast1", "australia-southeast2", "europe-central1", "europe-central2", "europe-north1", "europe-southwest1", "europe-west1", "europe-west2", "europe-west3", "europe-west4", "europe-west6", "europe-west7", "europe-west8", "europe-west9", "europe-west12", "me-central1", "me-central2", "me-west1", "northamerica-northeast1", "northamerica-northeast2", "southamerica-east1", "southamerica-west1", "us-central1", "us-east1", "us-east2", "us-east3", "us-east4", "us-east5", "us-south1", "us-west1", "us-west2", "us-west3", "us-west4" ], "group": "connection", "order": 1, "title": "Dataset Location", "type": "string" }, "destination": { "const": "airbyte-destination-bigquery", "type": "string" }, "disable_type_dedupe": { "default": false, "description": "Disable Writing Final Tables. WARNING! The data format in _airbyte_data is likely stable but there are no guarantees that other metadata columns will remain the same in future versions", "group": "advanced", "order": 8, "title": "Disable Final Tables. (WARNING! Unstable option; Columns in raw table schema might change between versions)", "type": "boolean" }, "loading_method": { "description": "The way data will be uploaded to BigQuery.", "display_type": "radio", "group": "connection", "oneOf": [ { "description": "<i>(recommended)</i> Writes large batches of records to a file, uploads the file to GCS, then uses COPY INTO to load your data into BigQuery. Provides best-in-class speed, reliability and scalability. Read more about GCS Staging <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging\">here</a>.", "properties": { "credential": { "description": "An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys\">here</a>.", "oneOf": [ { "properties": { "credential_type": { "const": "HMAC_KEY", "order": 0, "type": "string" }, "hmac_key_access_id": { "instillCredentialField": true, "description": "HMAC key access ID. When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long.", "examples": [ "1234567890abcdefghij1234" ], "order": 1, "title": "HMAC Key Access ID", "type": "string" }, "hmac_key_secret": { "instillCredentialField": true, "description": "The corresponding secret for the access ID. It is a 40-character base-64 encoded string.", "examples": [ "1234567890abcdefghij1234567890ABCDEFGHIJ" ], "order": 2, "title": "HMAC Key Secret", "type": "string" } }, "required": [ "credential_type", "hmac_key_access_id", "hmac_key_secret" ], "title": "HMAC key" } ], "order": 1, "title": "Credential", "type": "object" }, "gcs_bucket_name": { "description": "The name of the GCS bucket. Read more <a href=\"https://cloud.google.com/storage/docs/naming-buckets\">here</a>.", "examples": [ "airbyte_sync" ], "order": 2, "title": "GCS Bucket Name", "type": "string" }, "gcs_bucket_path": { "description": "Directory under the GCS bucket where data will be written.", "examples": [ "data_sync/test" ], "order": 3, "title": "GCS Bucket Path", "type": "string" }, "keep_files_in_gcs-bucket": { "default": "Delete all tmp files from GCS", "description": "This upload method is supposed to temporary store records in GCS bucket. By this select you can chose if these records should be removed from GCS when migration has finished. The default \"Delete all tmp files from GCS\" value is used if not set explicitly.", "enum": [ "Delete all tmp files from GCS", "Keep all tmp files in GCS" ], "order": 4, "title": "GCS Tmp Files Afterward Processing", "type": "string" }, "method": { "const": "GCS Staging", "order": 0, "type": "string" } }, "required": [ "method", "gcs_bucket_name", "gcs_bucket_path", "credential" ], "title": "GCS Staging" }, { "description": "<i>(not recommended)</i> Direct loading using SQL INSERT statements. This method is extremely inefficient and provided only for quick testing. In all other cases, you should use GCS staging.", "properties": { "method": { "const": "Standard", "type": "string" } }, "required": [ "method" ], "title": "Standard Inserts" } ], "order": 3, "title": "Loading Method", "type": "object" }, "project_id": { "description": "The GCP project ID for the project containing the target BigQuery dataset. Read more <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects\">here</a>.", "group": "connection", "order": 0, "title": "Project ID", "type": "string" }, "raw_data_dataset": { "description": "The dataset to write raw tables into (default: airbyte_internal)", "group": "advanced", "order": 7, "title": "Raw Table Dataset Name", "type": "string" }, "transformation_priority": { "default": "interactive", "description": "Interactive run type means that the query is executed as soon as possible, and these queries count towards concurrent rate limit and daily limit. Read more about interactive run type <a href=\"https://cloud.google.com/bigquery/docs/running-queries#queries\">here</a>. Batch queries are queued and started as soon as idle resources are available in the BigQuery shared resource pool, which usually occurs within a few minutes. Batch queries donâ€™t count towards your concurrent rate limit. Read more about batch queries <a href=\"https://cloud.google.com/bigquery/docs/running-queries#batch\">here</a>. The default \"interactive\" value is used if not set explicitly.", "enum": [ "interactive", "batch" ], "group": "advanced", "order": 5, "title": "Transformation Query Run Type", "type": "string" } }, "required": [ "project_id", "dataset_location", "dataset_id", "destination" ], "title": "Bigquery", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "address": { "description": "Address to connect to.", "examples": [ "localhost,127.0.0.1" ], "order": 3, "title": "Address", "type": "string" }, "datacenter": { "default": "datacenter1", "description": "Datacenter of the cassandra cluster.", "order": 5, "title": "Datacenter", "type": "string" }, "destination": { "const": "airbyte-destination-cassandra", "type": "string" }, "keyspace": { "description": "Default Cassandra keyspace to create data in.", "order": 0, "title": "Keyspace", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with Cassandra.", "order": 2, "title": "Password", "type": "string" }, "port": { "default": 9042, "description": "Port of Cassandra.", "maximum": 65536, "minimum": 0, "order": 4, "title": "Port", "type": "integer" }, "replication": { "default": 1, "description": "Indicates to how many nodes the data should be replicated to.", "order": 6, "title": "Replication factor", "type": "integer" }, "username": { "description": "Username to use to access Cassandra.", "order": 1, "title": "Username", "type": "string" } }, "required": [ "keyspace", "username", "password", "address", "port", "destination" ], "title": "Cassandra", "type": "object" }, { "description": "The configuration model for the Vector DB based destinations. This model is used to generate the UI for the destination configuration,\nas well as to provide type safety for the configuration passed to the destination.\n\nThe configuration model is composed of four parts:\n* Processing configuration\n* Embedding configuration\n* Indexing configuration\n* Advanced configuration\n\nProcessing, embedding and advanced configuration are provided by this base class, while the indexing configuration is provided by the destination connector in the sub class.", "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "destination": { "const": "airbyte-destination-chroma", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "api_base": { "description": "The base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "https://your-resource-name.openai.azure.com" ], "title": "Resource base URL", "type": "string" }, "deployment": { "description": "The deployment for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "your-resource-name" ], "title": "Deployment", "type": "string" }, "mode": { "const": "azure_openai", "default": "azure_openai", "enum": [ "azure_openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "description": "The API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "title": "Azure OpenAI API key", "type": "string" } }, "required": [ "openai_key", "api_base", "deployment", "mode" ], "title": "Azure OpenAI", "type": "object" }, { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key", "mode" ], "title": "OpenAI", "type": "object" }, { "description": "Use the Cohere API to embed text.", "properties": { "cohere_key": { "instillCredentialField": true, "title": "Cohere API key", "type": "string" }, "mode": { "const": "cohere", "default": "cohere", "enum": [ "cohere" ], "title": "Mode", "type": "string" } }, "required": [ "cohere_key", "mode" ], "title": "Cohere", "type": "object" }, { "description": "Use a field in the record as the embedding. This is useful if you already have an embedding for your data and want to store it in the vector store.", "properties": { "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "field_name": { "description": "Name of the field in the record that contains the embedding", "examples": [ "embedding", "vector" ], "title": "Field name", "type": "string" }, "mode": { "const": "from_field", "default": "from_field", "enum": [ "from_field" ], "title": "Mode", "type": "string" } }, "required": [ "field_name", "dimensions", "mode" ], "title": "From Field", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "Fake", "type": "object" }, { "description": "Use a service that's compatible with the OpenAI API to embed text.", "properties": { "api_key": { "instillCredentialField": true, "default": "", "title": "API key", "type": "string" }, "base_url": { "description": "The base URL for your OpenAI-compatible service", "examples": [ "https://your-service-name.com" ], "title": "Base URL", "type": "string" }, "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "mode": { "const": "openai_compatible", "default": "openai_compatible", "enum": [ "openai_compatible" ], "title": "Mode", "type": "string" }, "model_name": { "default": "text-embedding-ada-002", "description": "The name of the model to use for embedding", "examples": [ "text-embedding-ada-002" ], "title": "Model name", "type": "string" } }, "required": [ "base_url", "dimensions", "mode" ], "title": "OpenAI-compatible", "type": "object" }, { "description": "Do not calculate embeddings. Chromadb uses the sentence transfomer (https://www.sbert.net/index.html) as a default if an embedding function is not defined. Note that depending on your hardware, calculating embeddings locally can be very slow and is mostly suited for prototypes.", "properties": { "mode": { "const": "no_embedding", "default": "no_embedding", "enum": [ "no_embedding" ], "title": "Mode", "type": "string" } }, "title": "Chroma Default Embedding Function", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Indexing configuration", "group": "indexing", "properties": { "auth_method": { "description": "Mode how to connect to Chroma", "oneOf": [ { "description": "Configure Chroma to save and load from your local machine", "properties": { "mode": { "const": "persistent_client", "default": "persistent_client", "enum": [ "persistent_client" ], "title": "Mode", "type": "string" }, "path": { "description": "Where Chroma will store its database files on disk, and load them on start.", "title": "Path", "type": "string" } }, "required": [ "path" ], "title": "Persistent Client Mode", "type": "object" }, { "description": "Authenticate using username and password (suitable for self-managed Chroma clusters)", "properties": { "host": { "description": "The URL to the chromadb instance", "order": 0, "title": "Host", "type": "string" }, "mode": { "const": "http_client", "default": "http_client", "enum": [ "http_client" ], "title": "Mode", "type": "string" }, "password": { "instillCredentialField": true, "default": "", "description": "Password used in server/client mode only", "order": 4, "title": "Password", "type": "string" }, "port": { "description": "The port to the chromadb instance", "order": 1, "title": "Port", "type": "integer" }, "ssl": { "description": "Whether to use SSL to connect to the Chroma server", "order": 2, "title": "SSL", "type": "boolean" }, "username": { "default": "", "description": "Username used in server/client mode only", "order": 3, "title": "Username", "type": "string" } }, "required": [ "host", "port", "ssl" ], "title": "Client/Server Mode", "type": "object" } ], "order": 0, "title": "Connection Mode", "type": "object" }, "collection_name": { "description": "The collection to load data into", "order": 3, "title": "Collection Name", "type": "string" } }, "required": [ "auth_method", "collection_name" ], "title": "Indexing", "type": "object" }, "omit_raw_text": { "default": false, "description": "Do not store the text that gets embedded along with the vector and the metadata in the destination. If set to true, only the vector and the metadata will be stored - in this case raw text for LLM use cases needs to be retrieved from another source.", "group": "advanced", "title": "Do not store raw text", "type": "boolean" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "minimum": 1, "title": "Chunk size", "type": "integer" }, "field_name_mappings": { "default": [], "description": "List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation.", "items": { "properties": { "from_field": { "description": "The field name in the source", "title": "From field name", "type": "string" }, "to_field": { "description": "The field name to use in the destination", "title": "To field name", "type": "string" } }, "required": [ "from_field", "to_field" ], "title": "FieldNameMappingConfigModel", "type": "object" }, "title": "Field name mappings", "type": "array" }, "metadata_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path.", "examples": [ "age", "user", "user.name" ], "items": { "type": "string" }, "title": "Fields to store as metadata", "type": "array" }, "text_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" }, "text_splitter": { "description": "Split text fields into chunks based on the specified method.", "oneOf": [ { "description": "Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc.", "properties": { "keep_separator": { "default": false, "description": "Whether to keep the separator in the resulting chunks", "title": "Keep separator", "type": "boolean" }, "mode": { "const": "separator", "default": "separator", "enum": [ "separator" ], "title": "Mode", "type": "string" }, "separators": { "default": [ "\"\\n\\n\"", "\"\\n\"", "\" \"", "\"\"" ], "description": "List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \".\". To split by a newline, use \"\\n\".", "items": { "type": "string" }, "title": "Separators", "type": "array" } }, "required": [ "mode" ], "title": "By Separator", "type": "object" }, { "description": "Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk.", "properties": { "mode": { "const": "markdown", "default": "markdown", "enum": [ "markdown" ], "title": "Mode", "type": "string" }, "split_level": { "default": 1, "description": "Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points", "maximum": 6, "minimum": 1, "title": "Split level", "type": "integer" } }, "required": [ "mode" ], "title": "By Markdown header", "type": "object" }, { "description": "Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks.", "properties": { "language": { "description": "Split code in suitable places based on the programming language", "enum": [ "cpp", "go", "java", "js", "php", "proto", "python", "rst", "ruby", "rust", "scala", "swift", "markdown", "latex", "html", "sol" ], "title": "Language", "type": "string" }, "mode": { "const": "code", "default": "code", "enum": [ "code" ], "title": "Mode", "type": "string" } }, "required": [ "language", "mode" ], "title": "By Programming Language", "type": "object" } ], "title": "Text splitter", "type": "object" } }, "required": [ "chunk_size" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "embedding", "processing", "indexing", "destination" ], "title": "Chroma", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-clickhouse", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 5, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 8123, "description": "HTTP port of the database.", "examples": [ "8123" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "ssl": { "default": false, "description": "Encrypt data using SSL.", "order": 6, "title": "SSL Connection", "type": "boolean" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "database", "username", "destination" ], "title": "Clickhouse", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "access_key": { "instillCredentialField": "true", "description": "API access key used to send data to a Convex deployment.", "type": "string" }, "deployment_url": { "description": "URL of the Convex deployment that is the destination", "examples": [ "https://murky-swan-635.convex.cloud", "https://cluttered-owl-337.convex.cloud" ], "type": "string" }, "destination": { "const": "airbyte-destination-convex", "type": "string" } }, "required": [ "deployment_url", "access_key", "destination" ], "title": "Convex", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "delimiter_type": { "description": "The character delimiting individual cells in the CSV data.", "oneOf": [ { "properties": { "delimiter": { "const": "\\u002c", "type": "string" } }, "required": [ "delimiter" ], "title": "Comma" }, { "properties": { "delimiter": { "const": "\\u003b", "type": "string" } }, "required": [ "delimiter" ], "title": "Semicolon" }, { "properties": { "delimiter": { "const": "\\u007c", "type": "string" } }, "required": [ "delimiter" ], "title": "Pipe" }, { "properties": { "delimiter": { "const": "\\u0009", "type": "string" } }, "required": [ "delimiter" ], "title": "Tab" }, { "properties": { "delimiter": { "const": "\\u0020", "type": "string" } }, "required": [ "delimiter" ], "title": "Space" } ], "title": "Delimiter", "type": "object" }, "destination": { "const": "airbyte-destination-csv", "type": "string" }, "destination_path": { "description": "Path to the directory where csv files will be written. The destination uses the local mount \"/local\" and any data files will be placed inside that local mount. For more information check out our <a href=\"https://docs.airbyte.com/integrations/destinations/local-csv\">docs</a>", "examples": [ "/local" ], "type": "string" } }, "required": [ "destination_path", "destination" ], "title": "Csv", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "api_host": { "default": "https://api.cumul.io", "description": "URL of the Cumul.io API (e.g. 'https://api.cumul.io', 'https://api.us.cumul.io', or VPC-specific API url). Defaults to 'https://api.cumul.io'.", "order": 0, "title": "Cumul.io API Host URL", "type": "string" }, "api_key": { "instillCredentialField": true, "description": "An API key generated in Cumul.io's platform (can be generated here: https://app.cumul.io/start/profile/integration).", "order": 1, "title": "Cumul.io API Key", "type": "string" }, "api_token": { "instillCredentialField": true, "description": "The corresponding API token generated in Cumul.io's platform (can be generated here: https://app.cumul.io/start/profile/integration).", "order": 2, "title": "Cumul.io API Token", "type": "string" }, "destination": { "const": "airbyte-destination-cumulio", "type": "string" } }, "required": [ "api_host", "api_key", "api_token", "destination" ], "title": "Cumulio", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 3, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-databend", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 6, "title": "Password", "type": "string" }, "port": { "default": 443, "description": "Port of the database.", "examples": [ "443" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "Port", "type": "integer" }, "table": { "default": "default", "description": "The default table was written to.", "examples": [ "default" ], "order": 4, "title": "Default Table", "type": "string" }, "username": { "description": "Username to use to access the database.", "order": 5, "title": "User", "type": "string" } }, "required": [ "host", "username", "database", "destination" ], "title": "Databend", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "accept_terms": { "default": false, "description": "You must agree to the Databricks JDBC Driver <a href=\"https://databricks.com/jdbc-odbc-driver-license\">Terms & Conditions</a> to use this connector.", "order": 1, "title": "Agree to the Databricks JDBC Driver Terms & Conditions", "type": "boolean" }, "data_source": { "default": "MANAGED_TABLES_STORAGE", "description": "Storage on which the delta lake is built.", "oneOf": [ { "properties": { "data_source_type": { "const": "MANAGED_TABLES_STORAGE", "order": 0, "type": "string" } }, "required": [ "data_source_type" ], "title": "[Recommended] Managed tables" }, { "properties": { "data_source_type": { "const": "S3_STORAGE", "order": 1, "type": "string" }, "file_name_pattern": { "description": "The pattern allows you to set the file-name format for the S3 staging file(s)", "examples": [ "{date}", "{date:yyyy_MM}", "{timestamp}", "{part_number}", "{sync_id}" ], "order": 7, "title": "S3 Filename pattern", "type": "string" }, "s3_access_key_id": { "instillCredentialField": true, "description": "The Access Key Id granting allow one to access the above S3 staging bucket. Airbyte requires Read and Write permissions to the given bucket.", "examples": [ "A012345678910EXAMPLE" ], "order": 5, "title": "S3 Access Key ID", "type": "string" }, "s3_bucket_name": { "description": "The name of the S3 bucket to use for intermittent staging of the data.", "examples": [ "airbyte.staging" ], "order": 2, "title": "S3 Bucket Name", "type": "string" }, "s3_bucket_path": { "description": "The directory under the S3 bucket where data will be written.", "examples": [ "data_sync/test" ], "order": 3, "title": "S3 Bucket Path", "type": "string" }, "s3_bucket_region": { "default": "", "description": "The region of the S3 staging bucket to use if utilising a copy strategy.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 4, "title": "S3 Bucket Region", "type": "string" }, "s3_secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the above access key id.", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "order": 6, "title": "S3 Secret Access Key", "type": "string" } }, "required": [ "data_source_type", "s3_bucket_name", "s3_bucket_path", "s3_bucket_region", "s3_access_key_id", "s3_secret_access_key" ], "title": "Amazon S3" }, { "properties": { "azure_blob_storage_account_name": { "description": "The account's name of the Azure Blob Storage.", "examples": [ "airbyte5storage" ], "order": 2, "title": "Azure Blob Storage Account Name", "type": "string" }, "azure_blob_storage_container_name": { "description": "The name of the Azure blob storage container.", "examples": [ "airbytetestcontainername" ], "order": 3, "title": "Azure Blob Storage Container Name", "type": "string" }, "azure_blob_storage_endpoint_domain_name": { "default": "blob.core.windows.net", "description": "This is Azure Blob Storage endpoint domain name. Leave default value (or leave it empty if run container from command line) to use Microsoft native from example.", "examples": [ "blob.core.windows.net" ], "order": 1, "title": "Endpoint Domain Name", "type": "string" }, "azure_blob_storage_sas_token": { "instillCredentialField": true, "description": "Shared access signature (SAS) token to grant limited access to objects in your storage account.", "examples": [ "?sv=2016-05-31&ss=b&srt=sco&sp=rwdl&se=2018-06-27T10:05:50Z&st=2017-06-27T02:05:50Z&spr=https,http&sig=bgqQwoXwxzuD2GJfagRg7VOS8hzNr3QLT7rhS8OFRLQ%3D" ], "order": 4, "title": "SAS Token", "type": "string" }, "data_source_type": { "const": "AZURE_BLOB_STORAGE", "order": 0, "type": "string" } }, "required": [ "data_source_type", "azure_blob_storage_account_name", "azure_blob_storage_container_name", "azure_blob_storage_sas_token" ], "title": "Azure Blob Storage" } ], "order": 9, "title": "Data Source", "type": "object" }, "database": { "description": "The name of the catalog. If not specified otherwise, the \"hive_metastore\" will be used.", "order": 6, "title": "Databricks catalog", "type": "string" }, "databricks_http_path": { "description": "Databricks Cluster HTTP Path.", "examples": [ "sql/protocolvx/o/1234567489/0000-1111111-abcd90" ], "order": 3, "title": "HTTP Path", "type": "string" }, "databricks_personal_access_token": { "instillCredentialField": true, "description": "Databricks Personal Access Token for making authenticated requests.", "examples": [ "dapi0123456789abcdefghij0123456789AB" ], "order": 5, "title": "Access Token", "type": "string" }, "databricks_port": { "default": "443", "description": "Databricks Cluster Port.", "examples": [ "443" ], "order": 4, "title": "Port", "type": "string" }, "databricks_server_hostname": { "description": "Databricks Cluster Server Hostname.", "examples": [ "abc-12345678-wxyz.cloud.databricks.com" ], "order": 2, "title": "Server Hostname", "type": "string" }, "destination": { "const": "airbyte-destination-databricks", "type": "string" }, "enable_schema_evolution": { "default": false, "description": "Support schema evolution for all streams. If \"false\", the connector might fail when a stream's schema changes.", "order": 8, "title": "Support schema evolution for all streams.", "type": "boolean" }, "purge_staging_data": { "default": true, "description": "Default to 'true'. Switch it to 'false' for debugging purpose.", "order": 10, "title": "Purge Staging Files and Tables", "type": "boolean" }, "schema": { "default": "default", "description": "The default schema tables are written. If not specified otherwise, the \"default\" will be used.", "examples": [ "default" ], "order": 7, "title": "Default Schema", "type": "string" } }, "required": [ "accept_terms", "databricks_server_hostname", "databricks_http_path", "databricks_personal_access_token", "data_source", "destination" ], "title": "Databricks", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "database": { "description": "Name of the database.", "order": 3, "title": "DataBase Name", "type": "string" }, "destination": { "const": "airbyte-destination-doris", "type": "string" }, "host": { "description": "Hostname of the database", "order": 0, "title": "Host", "type": "string" }, "httpport": { "default": 8030, "description": "Http Port of the database.", "examples": [ "8030" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "HttpPort", "type": "integer" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 5, "title": "Password", "type": "string" }, "queryport": { "default": 9030, "description": "Query(SQL) Port of the database.", "examples": [ "9030" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "QueryPort", "type": "integer" }, "username": { "description": "Username to use to access the database.", "order": 4, "title": "UserName", "type": "string" } }, "required": [ "host", "httpport", "queryport", "username", "database", "destination" ], "title": "Doris", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "destination": { "const": "airbyte-destination-duckdb", "type": "string" }, "destination_path": { "description": "Path to the .duckdb file, or the text 'md:' to connect to MotherDuck. The file will be placed inside that local mount. For more information check out our <a href=\"https://docs.airbyte.io/integrations/destinations/duckdb\">docs</a>", "examples": [ "/local/destination.duckdb", "md:", "motherduck:" ], "title": "Destination DB", "type": "string" }, "motherduck_api_key": { "instillCredentialField": true, "description": "API key to use for authentication to a MotherDuck database.", "title": "MotherDuck API Key", "type": "string" }, "schema": { "description": "Database schema name, default for duckdb is 'main'.", "example": "main", "title": "Destination Schema", "type": "string" } }, "required": [ "destination_path", "destination" ], "title": "Duckdb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "access_key_id": { "instillCredentialField": true, "description": "The access key id to access the DynamoDB. Airbyte requires Read and Write permissions to the DynamoDB.", "examples": [ "A012345678910EXAMPLE" ], "title": "DynamoDB Key Id", "type": "string" }, "destination": { "const": "airbyte-destination-dynamodb", "type": "string" }, "dynamodb_endpoint": { "default": "", "description": "This is your DynamoDB endpoint url.(if you are working with AWS DynamoDB, just leave empty).", "examples": [ "http://localhost:9000" ], "title": "Endpoint", "type": "string" }, "dynamodb_region": { "default": "", "description": "The region of the DynamoDB.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "title": "DynamoDB Region", "type": "string" }, "dynamodb_table_name_prefix": { "description": "The prefix to use when naming DynamoDB tables.", "examples": [ "airbyte_sync" ], "title": "Table name prefix", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the access key id.", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "title": "DynamoDB Access Key", "type": "string" } }, "required": [ "dynamodb_table_name_prefix", "dynamodb_region", "access_key_id", "secret_access_key", "destination" ], "title": "Dynamodb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "destination": { "const": "airbyte-destination-e2e-test", "type": "string" }, "test_destination": { "description": "The type of destination to be used", "oneOf": [ { "properties": { "logging_config": { "description": "Configurate how the messages are logged.", "oneOf": [ { "description": "Log first N entries per stream.", "properties": { "logging_type": { "default": "FirstN", "enum": [ "FirstN" ], "type": "string" }, "max_entry_count": { "default": 100, "description": "Number of entries to log. This destination is for testing only. So it won't make sense to log infinitely. The maximum is 1,000 entries.", "examples": [ 100 ], "maximum": 1000, "minimum": 1, "title": "N", "type": "number" } }, "required": [ "logging_type", "max_entry_count" ], "title": "First N Entries", "type": "object" }, { "description": "For each stream, log every N-th entry with a maximum cap.", "properties": { "logging_type": { "default": "EveryNth", "enum": [ "EveryNth" ], "type": "string" }, "max_entry_count": { "default": 100, "description": "Max number of entries to log. This destination is for testing only. So it won't make sense to log infinitely. The maximum is 1,000 entries.", "examples": [ 100 ], "maximum": 1000, "minimum": 1, "title": "Max Log Entries", "type": "number" }, "nth_entry_to_log": { "description": "The N-th entry to log for each stream. N starts from 1. For example, when N = 1, every entry is logged; when N = 2, every other entry is logged; when N = 3, one out of three entries is logged.", "example": [ 3 ], "maximum": 1000, "minimum": 1, "title": "N", "type": "number" } }, "required": [ "logging_type", "nth_entry_to_log", "max_entry_count" ], "title": "Every N-th Entry", "type": "object" }, { "description": "For each stream, randomly log a percentage of the entries with a maximum cap.", "properties": { "logging_type": { "default": "RandomSampling", "enum": [ "RandomSampling" ], "type": "string" }, "max_entry_count": { "default": 100, "description": "Max number of entries to log. This destination is for testing only. So it won't make sense to log infinitely. The maximum is 1,000 entries.", "examples": [ 100 ], "maximum": 1000, "minimum": 1, "title": "Max Log Entries", "type": "number" }, "sampling_ratio": { "default": 0.001, "description": "A positive floating number smaller than 1.", "examples": [ 0.001 ], "maximum": 1, "minimum": 0, "title": "Sampling Ratio", "type": "number" }, "seed": { "description": "When the seed is unspecified, the current time millis will be used as the seed.", "examples": [ 1900 ], "title": "Random Number Generator Seed", "type": "number" } }, "required": [ "logging_type", "sampling_ratio", "max_entry_count" ], "title": "Random Sampling", "type": "object" } ], "title": "Logging Configuration", "type": "object" }, "test_destination_type": { "const": "LOGGING", "default": "LOGGING", "type": "string" } }, "required": [ "test_destination_type", "logging_config" ], "title": "Logging" }, { "properties": { "test_destination_type": { "const": "SILENT", "default": "SILENT", "type": "string" } }, "required": [ "test_destination_type" ], "title": "Silent" }, { "properties": { "millis_per_record": { "description": "Number of milli-second to pause in between records.", "type": "integer" }, "test_destination_type": { "const": "THROTTLED", "default": "THROTTLED", "type": "string" } }, "required": [ "test_destination_type", "millis_per_record" ], "title": "Throttled" }, { "properties": { "num_messages": { "description": "Number of messages after which to fail.", "type": "integer" }, "test_destination_type": { "const": "FAILING", "default": "FAILING", "type": "string" } }, "required": [ "test_destination_type", "num_messages" ], "title": "Failing" } ], "title": "Test Destination", "type": "object" } }, "required": [ "test_destination", "destination" ], "title": "E2etest", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "authenticationMethod": { "description": "The type of authentication to be used", "oneOf": [ { "additionalProperties": false, "description": "No authentication will be used", "properties": { "method": { "const": "none", "type": "string" } }, "required": [ "method" ], "title": "None" }, { "additionalProperties": false, "description": "Use a api key and secret combination to authenticate", "properties": { "apiKeyId": { "description": "The Key ID to used when accessing an enterprise Elasticsearch instance.", "title": "API Key ID", "type": "string" }, "apiKeySecret": { "instillCredentialField": true, "description": "The secret associated with the API Key ID.", "title": "API Key Secret", "type": "string" }, "method": { "const": "secret", "type": "string" } }, "required": [ "method", "apiKeyId", "apiKeySecret" ], "title": "Api Key/Secret" }, { "additionalProperties": false, "description": "Basic auth header with a username and password", "properties": { "method": { "const": "basic", "type": "string" }, "password": { "instillCredentialField": true, "description": "Basic auth password to access a secure Elasticsearch server", "title": "Password", "type": "string" }, "username": { "description": "Basic auth username to access a secure Elasticsearch server", "title": "Username", "type": "string" } }, "required": [ "method", "username", "password" ], "title": "Username/Password" } ], "title": "Authentication Method", "type": "object" }, "ca_certificate": { "instillCredentialField": true, "description": "CA certificate", "multiline": true, "title": "CA certificate", "type": "string" }, "destination": { "const": "airbyte-destination-elasticsearch", "type": "string" }, "endpoint": { "description": "The full url of the Elasticsearch server", "title": "Server Endpoint", "type": "string" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "upsert": { "default": true, "description": "If a primary key identifier is defined in the source, an upsert will be performed using the primary key value as the elasticsearch doc id. Does not support composite primary keys.", "title": "Upsert Records", "type": "boolean" } }, "required": [ "endpoint", "destination" ], "title": "Elasticsearch", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "certificateFingerprint": { "description": "Fingerprint of the Exasol server's TLS certificate", "examples": [ "ABC123..." ], "order": 2, "title": "Certificate Fingerprint", "type": "string" }, "destination": { "const": "airbyte-destination-exasol", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol ';'. (example: key1=value1;key2=value2;key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 8563, "description": "Port of the database.", "examples": [ "8563" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "description": "Schema Name", "order": 5, "title": "Schema Name", "type": "string" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "schema", "destination" ], "title": "Exasol", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "account": { "description": "Firebolt account to login.", "title": "Account", "type": "string" }, "database": { "description": "The database to connect to.", "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-firebolt", "type": "string" }, "engine": { "description": "Engine name or url to connect to.", "title": "Engine", "type": "string" }, "host": { "description": "The host name of your Firebolt database.", "examples": [ "api.app.firebolt.io" ], "title": "Host", "type": "string" }, "loading_method": { "description": "Loading method used to select the way data will be uploaded to Firebolt", "oneOf": [ { "additionalProperties": false, "properties": { "method": { "const": "SQL", "type": "string" } }, "required": [ "method" ], "title": "SQL Inserts" }, { "additionalProperties": false, "properties": { "aws_key_id": { "instillCredentialField": true, "description": "AWS access key granting read and write access to S3.", "title": "AWS Key ID", "type": "string" }, "aws_key_secret": { "instillCredentialField": true, "description": "Corresponding secret part of the AWS Key", "title": "AWS Key Secret", "type": "string" }, "method": { "const": "S3", "type": "string" }, "s3_bucket": { "description": "The name of the S3 bucket.", "title": "S3 bucket name", "type": "string" }, "s3_region": { "description": "Region name of the S3 bucket.", "examples": [ "us-east-1" ], "title": "S3 region name", "type": "string" } }, "required": [ "method", "s3_bucket", "s3_region", "aws_key_id", "aws_key_secret" ], "title": "External Table via S3" } ], "title": "Loading Method", "type": "object" }, "password": { "instillCredentialField": true, "description": "Firebolt password.", "order": 1, "title": "Password", "type": "string" }, "username": { "description": "Firebolt email address you use to login.", "examples": [ "username@email.com" ], "order": 0, "title": "Username", "type": "string" } }, "required": [ "username", "password", "database", "destination" ], "title": "Firebolt", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "credentials_json": { "instillCredentialField": true, "description": "The contents of the JSON service account key. Check out the <a href=\"https://docs.airbyte.io/integrations/destinations/firestore\">docs</a> if you need help generating this key. Default credentials will be used if this field is left empty.", "title": "Credentials JSON", "type": "string" }, "destination": { "const": "airbyte-destination-firestore", "type": "string" }, "project_id": { "description": "The GCP project ID for the project containing the target BigQuery dataset.", "title": "Project ID", "type": "string" } }, "required": [ "project_id", "destination" ], "title": "Firestore", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "credential": { "description": "An HMAC key is a type of credential and can be associated with a service account or a user account in Cloud Storage. Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys\">here</a>.", "oneOf": [ { "properties": { "credential_type": { "default": "HMAC_KEY", "enum": [ "HMAC_KEY" ], "type": "string" }, "hmac_key_access_id": { "instillCredentialField": true, "description": "When linked to a service account, this ID is 61 characters long; when linked to a user account, it is 24 characters long. Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys#overview\">here</a>.", "examples": [ "1234567890abcdefghij1234" ], "order": 0, "title": "Access ID", "type": "string" }, "hmac_key_secret": { "instillCredentialField": true, "description": "The corresponding secret for the access ID. It is a 40-character base-64 encoded string. Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys#secrets\">here</a>.", "examples": [ "1234567890abcdefghij1234567890ABCDEFGHIJ" ], "order": 1, "title": "Secret", "type": "string" } }, "required": [ "credential_type", "hmac_key_access_id", "hmac_key_secret" ], "title": "HMAC Key" } ], "order": 0, "title": "Authentication", "type": "object" }, "destination": { "const": "airbyte-destination-gcs", "type": "string" }, "format": { "description": "Output data format. One of the following formats must be selected - <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro\">AVRO</a> format, <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas\">PARQUET</a> format, <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table\">CSV</a> format, or <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table\">JSONL</a> format.", "oneOf": [ { "properties": { "compression_codec": { "description": "The compression algorithm used to compress data. Default to no compression.", "oneOf": [ { "properties": { "codec": { "default": "no compression", "enum": [ "no compression" ], "type": "string" } }, "required": [ "codec" ], "title": "No Compression" }, { "properties": { "codec": { "default": "Deflate", "enum": [ "Deflate" ], "type": "string" }, "compression_level": { "default": 0, "description": "0: no compression & fastest, 9: best compression & slowest.", "maximum": 9, "minimum": 0, "title": "Deflate level", "type": "integer" } }, "required": [ "codec" ], "title": "Deflate" }, { "properties": { "codec": { "default": "bzip2", "enum": [ "bzip2" ], "type": "string" } }, "required": [ "codec" ], "title": "bzip2" }, { "properties": { "codec": { "default": "xz", "enum": [ "xz" ], "type": "string" }, "compression_level": { "default": 6, "description": "The presets 0-3 are fast presets with medium compression. The presets 4-6 are fairly slow presets with high compression. The default preset is 6. The presets 7-9 are like the preset 6 but use bigger dictionaries and have higher compressor and decompressor memory requirements. Unless the uncompressed size of the file exceeds 8 MiB, 16 MiB, or 32 MiB, it is waste of memory to use the presets 7, 8, or 9, respectively. Read more <a href=\"https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-\">here</a> for details.", "maximum": 9, "minimum": 0, "title": "Compression Level", "type": "integer" } }, "required": [ "codec" ], "title": "xz" }, { "properties": { "codec": { "default": "zstandard", "enum": [ "zstandard" ], "type": "string" }, "compression_level": { "default": 3, "description": "Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.", "maximum": 22, "minimum": -5, "title": "Compression Level", "type": "integer" }, "include_checksum": { "default": false, "description": "If true, include a checksum with each data block.", "title": "Include Checksum", "type": "boolean" } }, "required": [ "codec" ], "title": "zstandard" }, { "properties": { "codec": { "default": "snappy", "enum": [ "snappy" ], "type": "string" } }, "required": [ "codec" ], "title": "snappy" } ], "title": "Compression Codec", "type": "object" }, "format_type": { "default": "Avro", "enum": [ "Avro" ], "type": "string" } }, "required": [ "format_type", "compression_codec" ], "title": "Avro: Apache Avro" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".csv.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "GZIP" } ], "title": "Compression", "type": "object" }, "flattening": { "default": "No flattening", "description": "Whether the input JSON data should be normalized (flattened) in the output CSV. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Normalization", "type": "string" }, "format_type": { "default": "CSV", "enum": [ "CSV" ], "type": "string" } }, "required": [ "format_type" ], "title": "CSV: Comma-Separated Values" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".jsonl.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": "compression_type", "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": "compression_type", "title": "GZIP" } ], "title": "Compression", "type": "object" }, "format_type": { "default": "JSONL", "enum": [ "JSONL" ], "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: newline-delimited JSON" }, { "properties": { "block_size_mb": { "default": 128, "description": "This is the size of a row group being buffered in memory. It limits the memory usage when writing. Larger values will improve the IO when reading, but consume more memory when writing. Default: 128 MB.", "examples": [ 128 ], "title": "Block Size (Row Group Size) (MB)", "type": "integer" }, "compression_codec": { "default": "UNCOMPRESSED", "description": "The compression algorithm used to compress data pages.", "enum": [ "UNCOMPRESSED", "SNAPPY", "GZIP", "LZO", "BROTLI", "LZ4", "ZSTD" ], "title": "Compression Codec", "type": "string" }, "dictionary_encoding": { "default": true, "description": "Default: true.", "title": "Dictionary Encoding", "type": "boolean" }, "dictionary_page_size_kb": { "default": 1024, "description": "There is one dictionary page per column per row group when dictionary encoding is used. The dictionary page size works like the page size but for dictionary. Default: 1024 KB.", "examples": [ 1024 ], "title": "Dictionary Page Size (KB)", "type": "integer" }, "format_type": { "default": "Parquet", "enum": [ "Parquet" ], "type": "string" }, "max_padding_size_mb": { "default": 8, "description": "Maximum size allowed as padding to align row groups. This is also the minimum size of a row group. Default: 8 MB.", "examples": [ 8 ], "title": "Max Padding Size (MB)", "type": "integer" }, "page_size_kb": { "default": 1024, "description": "The page size is for compression. A block is composed of pages. A page is the smallest unit that must be read fully to access a single record. If this value is too small, the compression will deteriorate. Default: 1024 KB.", "examples": [ 1024 ], "title": "Page Size (KB)", "type": "integer" } }, "required": [ "format_type" ], "title": "Parquet: Columnar Storage" } ], "order": 4, "title": "Output Format", "type": "object" }, "gcs_bucket_name": { "description": "You can find the bucket name in the App Engine Admin console Application Settings page, under the label Google Cloud Storage Bucket. Read more <a href=\"https://cloud.google.com/storage/docs/naming-buckets\">here</a>.", "examples": [ "airbyte_sync" ], "order": 1, "title": "GCS Bucket Name", "type": "string" }, "gcs_bucket_path": { "description": "GCS Bucket Path string Subdirectory under the above bucket to sync the data into.", "examples": [ "data_sync/test" ], "order": 2, "title": "GCS Bucket Path", "type": "string" }, "gcs_bucket_region": { "default": "us", "description": "Select a Region of the GCS Bucket. Read more <a href=\"https://cloud.google.com/storage/docs/locations\">here</a>.", "enum": [ "northamerica-northeast1", "northamerica-northeast2", "us-central1", "us-east1", "us-east4", "us-west1", "us-west2", "us-west3", "us-west4", "southamerica-east1", "southamerica-west1", "europe-central2", "europe-north1", "europe-west1", "europe-west2", "europe-west3", "europe-west4", "europe-west6", "asia-east1", "asia-east2", "asia-northeast1", "asia-northeast2", "asia-northeast3", "asia-south1", "asia-south2", "asia-southeast1", "asia-southeast2", "australia-southeast1", "australia-southeast2", "asia", "eu", "us", "asia1", "eur4", "nam4" ], "order": 3, "title": "GCS Bucket Region", "type": "string" } }, "required": [ "gcs_bucket_name", "gcs_bucket_path", "credential", "format", "destination" ], "title": "Gcs", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "credentials": { "description": "Google API Credentials for connecting to Google Sheets and Google Drive APIs", "properties": { "client_id": { "instillCredentialField": true, "description": "The Client ID of your Google Sheets developer application.", "title": "Client ID", "type": "string" }, "client_secret": { "instillCredentialField": true, "description": "The Client Secret of your Google Sheets developer application.", "title": "Client Secret", "type": "string" }, "refresh_token": { "instillCredentialField": true, "description": "The token for obtaining new access token.", "title": "Refresh Token", "type": "string" } }, "required": [ "client_id", "client_secret", "refresh_token" ], "title": "Authentication via Google (OAuth)", "type": "object" }, "destination": { "const": "airbyte-destination-google-sheets", "type": "string" }, "spreadsheet_id": { "description": "The link to your spreadsheet. See <a href='https://docs.airbyte.com/integrations/destinations/google-sheets#sheetlink'>this guide</a> for more details.", "examples": [ "https://docs.google.com/spreadsheets/d/1hLd9Qqti3UyLXZB2aFfUWDT7BG/edit" ], "title": "Spreadsheet Link", "type": "string" } }, "required": [ "spreadsheet_id", "credentials", "destination" ], "title": "Googlesheets", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "catalog_config": { "description": "Catalog config of Iceberg.", "oneOf": [ { "properties": { "catalog_type": { "default": "Hive", "enum": [ "Hive" ], "order": 0, "title": "Catalog Type", "type": "string" }, "database": { "default": "default", "description": "The default database tables are written to if the source does not specify a namespace. The usual value for this field is \"default\".", "examples": [ "default" ], "order": 2, "title": "Default database", "type": "string" }, "hive_thrift_uri": { "description": "Hive MetaStore thrift server uri of iceberg catalog.", "examples": [ "host:port" ], "order": 1, "title": "Hive Metastore thrift uri", "type": "string" } }, "required": [ "catalog_type", "hive_thrift_uri" ], "title": "HiveCatalog: Use Apache Hive MetaStore" }, { "description": "A Hadoop catalog doesnâ€™t need to connect to a Hive MetaStore, but can only be used with HDFS or similar file systems that support atomic rename.", "properties": { "catalog_type": { "default": "Hadoop", "enum": [ "Hadoop" ], "order": 0, "title": "Catalog Type", "type": "string" }, "database": { "default": "default", "description": "The default database tables are written to if the source does not specify a namespace. The usual value for this field is \"default\".", "examples": [ "default" ], "order": 1, "title": "Default database", "type": "string" } }, "required": [ "catalog_type" ], "title": "HadoopCatalog: Use hierarchical file systems as same as storage config" }, { "description": "Using a table in a relational database to manage Iceberg tables through JDBC. Read more <a href=\"https://iceberg.apache.org/docs/latest/jdbc/\">here</a>. Supporting: PostgreSQL", "properties": { "catalog_schema": { "default": "public", "description": "Iceberg catalog metadata tables are written to catalog schema. The usual value for this field is \"public\".", "examples": [ "public" ], "order": 6, "title": "schema for Iceberg catalog", "type": "string" }, "catalog_type": { "default": "Jdbc", "enum": [ "Jdbc" ], "order": 0, "title": "Catalog Type", "type": "string" }, "database": { "default": "public", "description": "The default schema tables are written to if the source does not specify a namespace. The usual value for this field is \"public\".", "examples": [ "public" ], "order": 1, "title": "Default schema", "type": "string" }, "jdbc_url": { "examples": [ "jdbc:postgresql://{host}:{port}/{database}" ], "order": 2, "title": "Jdbc url", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "ssl": { "default": false, "description": "Encrypt data using SSL. When activating SSL, please select one of the connection modes.", "order": 5, "title": "SSL Connection", "type": "boolean" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "catalog_type" ], "title": "JdbcCatalog: Use relational database" }, { "description": "The RESTCatalog connects to a REST server at the specified URI", "properties": { "catalog_type": { "default": "Rest", "enum": [ "Rest" ], "order": 0, "title": "Catalog Type", "type": "string" }, "rest_credential": { "instillCredentialField": true, "examples": [ "username:password" ], "order": 2, "title": "A credential to exchange for a token in the OAuth2 client credentials flow.", "type": "string" }, "rest_token": { "instillCredentialField": true, "examples": [ "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c" ], "order": 3, "title": "A Bearer token which will be used for interaction with the server.", "type": "string" }, "rest_uri": { "examples": [ "http://localhost:12345" ], "order": 1, "title": "REST Server URI", "type": "string" } }, "required": [ "catalog_type", "rest_uri" ], "title": "RESTCatalog" } ], "order": 0, "title": "Iceberg catalog config", "type": "object" }, "destination": { "const": "airbyte-destination-iceberg", "type": "string" }, "format_config": { "description": "File format of Iceberg storage.", "order": 2, "properties": { "auto_compact": { "default": false, "description": "Auto compact data files when stream close", "order": 2, "title": "Auto compact data files", "type": "boolean" }, "compact_target_file_size_in_mb": { "default": 100, "description": "Specify the target size of Iceberg data file when performing a compaction action. ", "order": 3, "title": "Target size of compacted data file", "type": "integer" }, "flush_batch_size": { "default": 10000, "description": "Iceberg data file flush batch size. Incoming rows write to cache firstly; When cache size reaches this 'batch size', flush into real Iceberg data file.", "order": 1, "title": "Data file flushing batch size", "type": "integer" }, "format": { "default": "Parquet", "description": "", "enum": [ "Parquet", "Avro" ], "order": 0, "title": "File storage format", "type": "string" } }, "required": [ "format" ], "title": "File format", "type": "object" }, "storage_config": { "description": "Storage config of Iceberg.", "oneOf": [ { "description": "S3 object storage", "properties": { "access_key_id": { "instillCredentialField": true, "description": "The access key ID to access the S3 bucket. Airbyte requires Read and Write permissions to the given bucket. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>.", "examples": [ "A012345678910EXAMPLE" ], "order": 0, "title": "S3 Key ID", "type": "string" }, "s3_bucket_region": { "default": "", "description": "The region of the S3 bucket. See <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions\">here</a> for all region codes.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 3, "title": "S3 Bucket Region", "type": "string" }, "s3_endpoint": { "default": "", "description": "Your S3 endpoint url. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/s3.html#:~:text=Service%20endpoints-,Amazon%20S3%20endpoints,-When%20you%20use\">here</a>", "examples": [ "http://localhost:9000", "localhost:9000" ], "order": 4, "title": "Endpoint", "type": "string" }, "s3_path_style_access": { "default": true, "description": "Use path style access", "examples": [ true, false ], "order": 5, "type": "boolean" }, "s3_warehouse_uri": { "description": "The Warehouse Uri for Iceberg", "examples": [ "s3a://my-bucket/path/to/warehouse", "s3://my-bucket/path/to/warehouse" ], "order": 2, "title": "S3 Warehouse Uri for Iceberg", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the access key ID. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "order": 1, "title": "S3 Access Key", "type": "string" }, "storage_type": { "default": "S3", "enum": [ "S3" ], "order": 0, "title": "Storage Type", "type": "string" } }, "required": [ "storage_type", "access_key_id", "secret_access_key", "s3_warehouse_uri" ], "title": "S3", "type": "object" }, { "description": "Server-managed object storage", "properties": { "managed_warehouse_name": { "description": "The name of the managed warehouse", "order": 0, "title": "Warehouse name", "type": "string" }, "storage_type": { "default": "MANAGED", "enum": [ "MANAGED" ], "order": 0, "title": "Storage Type", "type": "string" } }, "required": [ "storage_type", "managed_warehouse_name" ], "title": "Server-managed", "type": "object" } ], "order": 1, "title": "Storage config", "type": "object" } }, "required": [ "catalog_config", "storage_config", "format_config", "destination" ], "title": "Iceberg", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "acks": { "default": "1", "description": "The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent.", "enum": [ "0", "1", "all" ], "title": "ACKs", "type": "string" }, "batch_size": { "description": "The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.", "examples": [ 16384 ], "title": "Batch Size", "type": "integer" }, "bootstrap_servers": { "description": "A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).", "examples": [ "kafka-broker1:9092,kafka-broker2:9092" ], "title": "Bootstrap Servers", "type": "string" }, "buffer_memory": { "description": "The total bytes of memory the producer can use to buffer records waiting to be sent to the server.", "examples": 33554432, "title": "Buffer Memory", "type": "string" }, "client_dns_lookup": { "default": "use_all_dns_ips", "description": "Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses.", "enum": [ "default", "use_all_dns_ips", "resolve_canonical_bootstrap_servers_only", "use_all_dns_ips" ], "title": "Client DNS Lookup", "type": "string" }, "client_id": { "description": "An ID string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.", "examples": [ "airbyte-producer" ], "title": "Client ID", "type": "string" }, "compression_type": { "default": "none", "description": "The compression type for all data generated by the producer.", "enum": [ "none", "gzip", "snappy", "lz4", "zstd" ], "title": "Compression Type", "type": "string" }, "delivery_timeout_ms": { "description": "An upper bound on the time to report success or failure after a call to 'send()' returns.", "examples": [ 120000 ], "title": "Delivery Timeout", "type": "integer" }, "destination": { "const": "airbyte-destination-kafka", "type": "string" }, "enable_idempotence": { "default": false, "description": "When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.", "title": "Enable Idempotence", "type": "boolean" }, "linger_ms": { "description": "The producer groups together any records that arrive in between request transmissions into a single batched request.", "examples": [ 0 ], "title": "Linger ms", "type": "string" }, "max_block_ms": { "description": "The configuration controls how long the KafkaProducer's send(), partitionsFor(), initTransactions(), sendOffsetsToTransaction(), commitTransaction() and abortTransaction() methods will block.", "examples": [ 60000 ], "title": "Max Block ms", "type": "string" }, "max_in_flight_requests_per_connection": { "description": "The maximum number of unacknowledged requests the client will send on a single connection before blocking. Can be greater than 1, and the maximum value supported with idempotency is 5.", "examples": [ 5 ], "title": "Max in Flight Requests per Connection", "type": "integer" }, "max_request_size": { "description": "The maximum size of a request in bytes.", "examples": [ 1048576 ], "title": "Max Request Size", "type": "integer" }, "protocol": { "description": "Protocol used to communicate with brokers.", "oneOf": [ { "properties": { "security_protocol": { "default": "PLAINTEXT", "enum": [ "PLAINTEXT" ], "type": "string" } }, "required": [ "security_protocol" ], "title": "PLAINTEXT" }, { "properties": { "sasl_jaas_config": { "instillCredentialField": true, "default": "", "description": "JAAS login context parameters for SASL connections in the format used by JAAS configuration files.", "title": "SASL JAAS Config", "type": "string" }, "sasl_mechanism": { "default": "PLAIN", "description": "SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.", "enum": [ "PLAIN" ], "title": "SASL Mechanism", "type": "string" }, "security_protocol": { "default": "SASL_PLAINTEXT", "enum": [ "SASL_PLAINTEXT" ], "type": "string" } }, "required": [ "security_protocol", "sasl_mechanism", "sasl_jaas_config" ], "title": "SASL PLAINTEXT" }, { "properties": { "sasl_jaas_config": { "instillCredentialField": true, "default": "", "description": "JAAS login context parameters for SASL connections in the format used by JAAS configuration files.", "title": "SASL JAAS Config", "type": "string" }, "sasl_mechanism": { "default": "GSSAPI", "description": "SASL mechanism used for client connections. This may be any mechanism for which a security provider is available.", "enum": [ "GSSAPI", "OAUTHBEARER", "SCRAM-SHA-256", "SCRAM-SHA-512", "PLAIN" ], "title": "SASL Mechanism", "type": "string" }, "security_protocol": { "default": "SASL_SSL", "enum": [ "SASL_SSL" ], "type": "string" } }, "required": [ "security_protocol", "sasl_mechanism", "sasl_jaas_config" ], "title": "SASL SSL" } ], "title": "Protocol", "type": "object" }, "receive_buffer_bytes": { "description": "The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.", "examples": [ 32768 ], "title": "Receive Buffer bytes", "type": "integer" }, "request_timeout_ms": { "description": "The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.", "examples": [ 30000 ], "title": "Request Timeout", "type": "integer" }, "retries": { "description": "Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.", "examples": [ 2147483647 ], "title": "Retries", "type": "integer" }, "send_buffer_bytes": { "description": "The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.", "examples": [ 131072 ], "title": "Send Buffer bytes", "type": "integer" }, "socket_connection_setup_timeout_max_ms": { "description": "The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum.", "examples": [ 30000 ], "title": "Socket Connection Setup Max Timeout", "type": "string" }, "socket_connection_setup_timeout_ms": { "description": "The amount of time the client will wait for the socket connection to be established.", "examples": [ 10000 ], "title": "Socket Connection Setup Timeout", "type": "string" }, "sync_producer": { "default": false, "description": "Wait synchronously until the record has been sent to Kafka.", "title": "Sync Producer", "type": "boolean" }, "test_topic": { "description": "Topic to test if Airbyte can produce messages.", "examples": [ "test.topic" ], "title": "Test Topic", "type": "string" }, "topic_pattern": { "description": "Topic pattern in which the records will be sent. You can use patterns like '{namespace}' and/or '{stream}' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention.", "examples": [ "sample.topic", "{namespace}.{stream}.sample" ], "title": "Topic Pattern", "type": "string" } }, "required": [ "bootstrap_servers", "topic_pattern", "protocol", "acks", "enable_idempotence", "compression_type", "batch_size", "linger_ms", "max_in_flight_requests_per_connection", "client_dns_lookup", "buffer_memory", "max_request_size", "retries", "socket_connection_setup_timeout_ms", "socket_connection_setup_timeout_max_ms", "max_block_ms", "request_timeout_ms", "delivery_timeout_ms", "send_buffer_bytes", "receive_buffer_bytes", "destination" ], "title": "Kafka", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "api_key": { "instillCredentialField": true, "description": "To get Keen Master API Key, navigate to the Access tab from the left-hand, side panel and check the Project Details section.", "examples": [ "ABCDEFGHIJKLMNOPRSTUWXYZ" ], "title": "API Key", "type": "string" }, "destination": { "const": "airbyte-destination-keen", "type": "string" }, "infer_timestamp": { "default": true, "description": "Allow connector to guess keen.timestamp value based on the streamed data.", "title": "Infer Timestamp", "type": "boolean" }, "project_id": { "description": "To get Keen Project ID, navigate to the Access tab from the left-hand, side panel and check the Project Details section.", "examples": [ "58b4acc22ba938934e888322e" ], "title": "Project ID", "type": "string" } }, "required": [ "project_id", "api_key", "destination" ], "title": "Keen", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "accessKey": { "instillCredentialField": true, "description": "Generate the AWS Access Key for current user.", "order": 3, "title": "Access Key", "type": "string" }, "bufferSize": { "default": 100, "description": "Buffer size for storing kinesis records before being batch streamed.", "maximum": 500, "minimum": 1, "order": 5, "title": "Buffer Size", "type": "integer" }, "destination": { "const": "airbyte-destination-kinesis", "type": "string" }, "endpoint": { "description": "AWS Kinesis endpoint.", "examples": [ "kinesis.usâ€‘westâ€‘1.amazonaws.com" ], "order": 0, "title": "Endpoint", "type": "string" }, "privateKey": { "instillCredentialField": true, "description": "The AWS Private Key - a string of numbers and letters that are unique for each account, also known as a \"recovery phrase\".", "order": 4, "title": "Private Key", "type": "string" }, "region": { "description": "AWS region. Your account determines the Regions that are available to you.", "examples": [ "usâ€‘westâ€‘1" ], "order": 1, "title": "Region", "type": "string" }, "shardCount": { "default": 5, "description": "Number of shards to which the data should be streamed.", "order": 2, "title": "Shard Count", "type": "integer" } }, "required": [ "endpoint", "region", "shardCount", "accessKey", "privateKey", "bufferSize", "destination" ], "title": "Kinesis", "type": "object" }, { "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" } ], "properties": { "destination": { "const": "airbyte-destination-langchain", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key" ], "title": "OpenAI", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "title": "Fake", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Indexing configuration", "group": "indexing", "oneOf": [ { "description": "Pinecone is a popular vector store that can be used to store and retrieve embeddings. It is a managed service and can also be queried from outside of langchain.", "properties": { "index": { "description": "Pinecone index to use", "title": "Index", "type": "string" }, "mode": { "const": "pinecone", "default": "pinecone", "enum": [ "pinecone" ], "title": "Mode", "type": "string" }, "pinecone_environment": { "description": "Pinecone environment to use", "title": "Pinecone environment", "type": "string" }, "pinecone_key": { "instillCredentialField": true, "title": "Pinecone API key", "type": "string" } }, "required": [ "pinecone_key", "pinecone_environment", "index" ], "title": "Pinecone", "type": "object" }, { "description": "DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.", "properties": { "destination_path": { "description": "Path to the directory where hnswlib and meta data files will be written. The files will be placed inside that local mount. All files in the specified destination directory will be deleted on each run.", "examples": [ "/local/my_hnswlib_index" ], "title": "Destination Path", "type": "string" }, "mode": { "const": "DocArrayHnswSearch", "default": "DocArrayHnswSearch", "enum": [ "DocArrayHnswSearch" ], "title": "Mode", "type": "string" } }, "required": [ "destination_path" ], "title": "DocArrayHnswSearch", "type": "object" }, { "description": "Chroma is a popular vector store that can be used to store and retrieve embeddings. It will build its index in memory and persist it to disk by the end of the sync.", "properties": { "collection_name": { "default": "langchain", "description": "Name of the collection to use.", "title": "Collection Name", "type": "string" }, "destination_path": { "description": "Path to the directory where chroma files will be written. The files will be placed inside that local mount.", "examples": [ "/local/my_chroma_db" ], "title": "Destination Path", "type": "string" }, "mode": { "const": "chroma_local", "default": "chroma_local", "enum": [ "chroma_local" ], "title": "Mode", "type": "string" } }, "required": [ "destination_path" ], "title": "Chroma (local persistance)", "type": "object" } ], "title": "Indexing", "type": "object" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "title": "Chunk size", "type": "integer" }, "text_fields": { "always_show": true, "description": "List of fields in the record that should be used to calculate the embedding. All other fields are passed along as meta fields. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" } }, "required": [ "chunk_size", "text_fields" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "processing", "embedding", "indexing", "destination" ], "title": "Langchain", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "destination": { "const": "airbyte-destination-local-json", "type": "string" }, "destination_path": { "description": "Path to the directory where json files will be written. The files will be placed inside that local mount. For more information check out our <a href=\"https://docs.airbyte.io/integrations/destinations/local-json\">docs</a>", "examples": [ "/json_data" ], "title": "Destination Path", "type": "string" } }, "required": [ "destination_path", "destination" ], "title": "Localjson", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-mariadb-columnstore", "type": "string" }, "host": { "description": "The Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 5, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "The Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 3306, "description": "The Port of the database.", "examples": [ "3306" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "The Username which is used to access the database.", "order": 3, "title": "Username", "type": "string" } }, "required": [ "host", "port", "username", "database", "destination" ], "title": "Mariadbcolumnstore", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "api_key": { "instillCredentialField": true, "description": "MeiliSearch API Key. See the <a href=\"https://docs.airbyte.com/integrations/destinations/meilisearch\">docs</a> for more information on how to obtain this key.", "order": 1, "title": "API Key", "type": "string" }, "destination": { "const": "airbyte-destination-meilisearch", "type": "string" }, "host": { "description": "Hostname of the MeiliSearch instance.", "order": 0, "title": "Host", "type": "string" } }, "required": [ "host", "destination" ], "title": "Meilisearch", "type": "object" }, { "description": "The configuration model for the Vector DB based destinations. This model is used to generate the UI for the destination configuration,\nas well as to provide type safety for the configuration passed to the destination.\n\nThe configuration model is composed of four parts:\n* Processing configuration\n* Embedding configuration\n* Indexing configuration\n* Advanced configuration\n\nProcessing, embedding and advanced configuration are provided by this base class, while the indexing configuration is provided by the destination connector in the sub class.", "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "destination": { "const": "airbyte-destination-milvus", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key", "mode" ], "title": "OpenAI", "type": "object" }, { "description": "Use the Cohere API to embed text.", "properties": { "cohere_key": { "instillCredentialField": true, "title": "Cohere API key", "type": "string" }, "mode": { "const": "cohere", "default": "cohere", "enum": [ "cohere" ], "title": "Mode", "type": "string" } }, "required": [ "cohere_key", "mode" ], "title": "Cohere", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "Fake", "type": "object" }, { "description": "Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "api_base": { "description": "The base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "https://your-resource-name.openai.azure.com" ], "title": "Resource base URL", "type": "string" }, "deployment": { "description": "The deployment for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "your-resource-name" ], "title": "Deployment", "type": "string" }, "mode": { "const": "azure_openai", "default": "azure_openai", "enum": [ "azure_openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "description": "The API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "title": "Azure OpenAI API key", "type": "string" } }, "required": [ "openai_key", "api_base", "deployment", "mode" ], "title": "Azure OpenAI", "type": "object" }, { "description": "Use a service that's compatible with the OpenAI API to embed text.", "properties": { "api_key": { "instillCredentialField": true, "default": "", "title": "API key", "type": "string" }, "base_url": { "description": "The base URL for your OpenAI-compatible service", "examples": [ "https://your-service-name.com" ], "title": "Base URL", "type": "string" }, "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "mode": { "const": "openai_compatible", "default": "openai_compatible", "enum": [ "openai_compatible" ], "title": "Mode", "type": "string" }, "model_name": { "default": "text-embedding-ada-002", "description": "The name of the model to use for embedding", "examples": [ "text-embedding-ada-002" ], "title": "Model name", "type": "string" } }, "required": [ "base_url", "dimensions", "mode" ], "title": "OpenAI-compatible", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Indexing configuration", "group": "indexing", "properties": { "auth": { "description": "Authentication method", "oneOf": [ { "description": "Authenticate using an API token (suitable for Zilliz Cloud)", "properties": { "mode": { "const": "token", "default": "token", "enum": [ "token" ], "title": "Mode", "type": "string" }, "token": { "instillCredentialField": true, "description": "API Token for the Milvus instance", "title": "API Token", "type": "string" } }, "required": [ "token", "mode" ], "title": "API Token", "type": "object" }, { "description": "Authenticate using username and password (suitable for self-managed Milvus clusters)", "properties": { "mode": { "const": "username_password", "default": "username_password", "enum": [ "username_password" ], "title": "Mode", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password for the Milvus instance", "order": 2, "title": "Password", "type": "string" }, "username": { "description": "Username for the Milvus instance", "order": 1, "title": "Username", "type": "string" } }, "required": [ "username", "password", "mode" ], "title": "Username/Password", "type": "object" }, { "description": "Do not authenticate (suitable for locally running test clusters, do not use for clusters with public IP addresses)", "properties": { "mode": { "const": "no_auth", "default": "no_auth", "enum": [ "no_auth" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "No auth", "type": "object" } ], "order": 2, "title": "Authentication", "type": "object" }, "collection": { "description": "The collection to load data into", "order": 3, "title": "Collection Name", "type": "string" }, "db": { "default": "", "description": "The database to connect to", "title": "Database Name", "type": "string" }, "host": { "description": "The public endpoint of the Milvus instance. ", "examples": [ "https://my-instance.zone.zillizcloud.com", "tcp://host.docker.internal:19530", "tcp://my-local-milvus:19530" ], "order": 1, "title": "Public Endpoint", "type": "string" }, "text_field": { "default": "text", "description": "The field in the entity that contains the embedded text", "title": "Text Field", "type": "string" }, "vector_field": { "default": "vector", "description": "The field in the entity that contains the vector", "title": "Vector Field", "type": "string" } }, "required": [ "host", "collection", "auth" ], "title": "Indexing", "type": "object" }, "omit_raw_text": { "default": false, "description": "Do not store the text that gets embedded along with the vector and the metadata in the destination. If set to true, only the vector and the metadata will be stored - in this case raw text for LLM use cases needs to be retrieved from another source.", "group": "advanced", "title": "Do not store raw text", "type": "boolean" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "minimum": 1, "title": "Chunk size", "type": "integer" }, "field_name_mappings": { "default": [], "description": "List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation.", "items": { "properties": { "from_field": { "description": "The field name in the source", "title": "From field name", "type": "string" }, "to_field": { "description": "The field name to use in the destination", "title": "To field name", "type": "string" } }, "required": [ "from_field", "to_field" ], "title": "FieldNameMappingConfigModel", "type": "object" }, "title": "Field name mappings", "type": "array" }, "metadata_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path.", "examples": [ "age", "user", "user.name" ], "items": { "type": "string" }, "title": "Fields to store as metadata", "type": "array" }, "text_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" }, "text_splitter": { "description": "Split text fields into chunks based on the specified method.", "oneOf": [ { "description": "Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc.", "properties": { "keep_separator": { "default": false, "description": "Whether to keep the separator in the resulting chunks", "title": "Keep separator", "type": "boolean" }, "mode": { "const": "separator", "default": "separator", "enum": [ "separator" ], "title": "Mode", "type": "string" }, "separators": { "default": [ "\"\\n\\n\"", "\"\\n\"", "\" \"", "\"\"" ], "description": "List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \".\". To split by a newline, use \"\\n\".", "items": { "type": "string" }, "title": "Separators", "type": "array" } }, "required": [ "mode" ], "title": "By Separator", "type": "object" }, { "description": "Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk.", "properties": { "mode": { "const": "markdown", "default": "markdown", "enum": [ "markdown" ], "title": "Mode", "type": "string" }, "split_level": { "default": 1, "description": "Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points", "maximum": 6, "minimum": 1, "title": "Split level", "type": "integer" } }, "required": [ "mode" ], "title": "By Markdown header", "type": "object" }, { "description": "Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks.", "properties": { "language": { "description": "Split code in suitable places based on the programming language", "enum": [ "cpp", "go", "java", "js", "php", "proto", "python", "rst", "ruby", "rust", "scala", "swift", "markdown", "latex", "html", "sol" ], "title": "Language", "type": "string" }, "mode": { "const": "code", "default": "code", "enum": [ "code" ], "title": "Mode", "type": "string" } }, "required": [ "language", "mode" ], "title": "By Programming Language", "type": "object" } ], "title": "Text splitter", "type": "object" } }, "required": [ "chunk_size" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "embedding", "processing", "indexing", "destination" ], "title": "Milvus", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "auth_type": { "description": "Authorization type.", "oneOf": [ { "description": "None.", "properties": { "authorization": { "const": "none", "type": "string" } }, "required": [ "authorization" ], "title": "None", "type": "object" }, { "description": "Login/Password.", "properties": { "authorization": { "const": "login/password", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 2, "title": "Password", "type": "string" }, "username": { "description": "Username to use to access the database.", "order": 1, "title": "User", "type": "string" } }, "required": [ "authorization", "username", "password" ], "title": "Login/Password", "type": "object" } ], "title": "Authorization type", "type": "object" }, "database": { "description": "Name of the database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-mongodb", "type": "string" }, "instance_type": { "description": "MongoDb instance to connect to. For MongoDB Atlas and Replica Set TLS connection is used by default.", "oneOf": [ { "properties": { "host": { "description": "The Host of a Mongo database to be replicated.", "order": 0, "title": "Host", "type": "string" }, "instance": { "default": "standalone", "enum": [ "standalone" ], "type": "string" }, "port": { "default": 27017, "description": "The Port of a Mongo database to be replicated.", "examples": [ "27017" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "tls": { "default": false, "description": "Indicates whether TLS encryption protocol will be used to connect to MongoDB. It is recommended to use TLS connection if possible. For more information see <a href=\"https://docs.airbyte.com/integrations/sources/mongodb-v2\">documentation</a>.", "order": 2, "title": "TLS Connection", "type": "boolean" } }, "required": [ "instance", "host", "port" ], "title": "Standalone MongoDb Instance" }, { "properties": { "instance": { "default": "replica", "enum": [ "replica" ], "type": "string" }, "replica_set": { "description": "A replica set name.", "order": 1, "title": "Replica Set", "type": "string" }, "server_addresses": { "description": "The members of a replica set. Please specify `host`:`port` of each member seperated by comma.", "examples": [ "host1:27017,host2:27017,host3:27017" ], "order": 0, "title": "Server addresses", "type": "string" } }, "required": [ "instance", "server_addresses" ], "title": "Replica Set" }, { "properties": { "cluster_url": { "description": "URL of a cluster to connect to.", "order": 0, "title": "Cluster URL", "type": "string" }, "instance": { "default": "atlas", "enum": [ "atlas" ], "type": "string" } }, "required": [ "instance", "cluster_url" ], "title": "MongoDB Atlas" } ], "order": 0, "title": "MongoDb Instance Type", "type": "object" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" } }, "required": [ "database", "auth_type", "destination" ], "title": "Mongodb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "automatic_reconnect": { "default": true, "description": "Whether the client will automatically attempt to reconnect to the server if the connection is lost.", "title": "Automatic reconnect", "type": "boolean" }, "broker_host": { "description": "Host of the broker to connect to.", "title": "MQTT broker host", "type": "string" }, "broker_port": { "description": "Port of the broker.", "title": "MQTT broker port", "type": "integer" }, "clean_session": { "default": true, "description": "Whether the client and server should remember state across restarts and reconnects.", "title": "Clean session", "type": "boolean" }, "client": { "description": "A client identifier that is unique on the server being connected to.", "examples": [ "airbyte-client1" ], "title": "Client ID", "type": "string" }, "connect_timeout": { "default": 30, "description": " Maximum time interval (in seconds) the client will wait for the network connection to the MQTT server to be established.", "title": "Connect timeout", "type": "integer" }, "destination": { "const": "airbyte-destination-mqtt", "type": "string" }, "message_qos": { "default": "AT_LEAST_ONCE", "description": "Quality of service used for each message to be delivered.", "enum": [ "AT_MOST_ONCE", "AT_LEAST_ONCE", "EXACTLY_ONCE" ], "title": "Message QoS" }, "message_retained": { "default": false, "description": "Whether or not the publish message should be retained by the messaging engine.", "title": "Message retained", "type": "boolean" }, "password": { "instillCredentialField": true, "description": "Password to use for the connection.", "title": "Password", "type": "string" }, "publisher_sync": { "default": false, "description": "Wait synchronously until the record has been sent to the broker.", "title": "Sync publisher", "type": "boolean" }, "topic_pattern": { "description": "Topic pattern in which the records will be sent. You can use patterns like '{namespace}' and/or '{stream}' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention.", "examples": [ "sample.topic", "{namespace}/{stream}/sample" ], "title": "Topic pattern", "type": "string" }, "topic_test": { "description": "Topic to test if Airbyte can produce messages.", "examples": [ "test/topic" ], "title": "Test topic", "type": "string" }, "use_tls": { "default": false, "description": "Whether to use TLS encryption on the connection.", "title": "Use TLS", "type": "boolean" }, "username": { "description": "User name to use for the connection.", "title": "Username", "type": "string" } }, "required": [ "broker_host", "broker_port", "use_tls", "topic_pattern", "publisher_sync", "connect_timeout", "automatic_reconnect", "clean_session", "message_retained", "message_qos", "destination" ], "title": "Mqtt", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "database": { "description": "The name of the MSSQL database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-mssql", "type": "string" }, "host": { "description": "The host name of the MSSQL database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "The password associated with this username.", "order": 5, "title": "Password", "type": "string" }, "port": { "default": 1433, "description": "The port of the MSSQL database.", "examples": [ "1433" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "default": "public", "description": "The default schema tables are written to if the source does not specify a namespace. The usual value for this field is \"public\".", "examples": [ "public" ], "order": 3, "title": "Default Schema", "type": "string" }, "ssl_method": { "description": "The encryption method which is used to communicate with the database.", "oneOf": [ { "description": "The data transfer will not be encrypted.", "properties": { "ssl_method": { "const": "unencrypted", "default": "unencrypted", "enum": [ "unencrypted" ], "type": "string" } }, "required": [ "ssl_method" ], "title": "Unencrypted", "type": "object" }, { "description": "Use the certificate provided by the server without verification. (For testing purposes only!)", "properties": { "ssl_method": { "const": "encrypted_trust_server_certificate", "default": "encrypted_trust_server_certificate", "enum": [ "encrypted_trust_server_certificate" ], "type": "string" } }, "required": [ "ssl_method" ], "title": "Encrypted (trust server certificate)", "type": "object" }, { "description": "Verify and use the certificate provided by the server.", "properties": { "hostNameInCertificate": { "description": "Specifies the host name of the server. The value of this property must match the subject property of the certificate.", "order": 8, "title": "Host Name In Certificate", "type": "string" }, "ssl_method": { "const": "encrypted_verify_certificate", "default": "encrypted_verify_certificate", "enum": [ "encrypted_verify_certificate" ], "type": "string" } }, "required": [ "ssl_method", "trustStoreName", "trustStorePassword" ], "title": "Encrypted (verify certificate)", "type": "object" } ], "order": 7, "title": "SSL Method", "type": "object" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "The username which is used to access the database.", "order": 4, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "database", "schema", "destination" ], "title": "Mssql", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-mysql", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 3306, "description": "Port of the database.", "examples": [ "3306" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "ssl": { "default": true, "description": "Encrypt data using SSL.", "order": 5, "title": "SSL Connection", "type": "boolean" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "database", "destination" ], "title": "Mysql", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "destination": { "const": "airbyte-destination-oracle", "type": "string" }, "encryption": { "description": "The encryption method which is used when communicating with the database.", "oneOf": [ { "description": "Data transfer will not be encrypted.", "properties": { "encryption_method": { "const": "unencrypted", "default": "unencrypted", "enum": [ "unencrypted" ], "type": "string" } }, "required": [ "encryption_method" ], "title": "Unencrypted" }, { "description": "The native network encryption gives you the ability to encrypt database connections, without the configuration overhead of TCP/IP and SSL/TLS and without the need to open and listen on different ports.", "properties": { "encryption_algorithm": { "default": "AES256", "description": "This parameter defines the database encryption algorithm.", "enum": [ "AES256", "RC4_56", "3DES168" ], "title": "Encryption Algorithm", "type": "string" }, "encryption_method": { "const": "client_nne", "default": "client_nne", "enum": [ "client_nne" ], "type": "string" } }, "required": [ "encryption_method" ], "title": "Native Network Encryption (NNE)" }, { "description": "Verify and use the certificate provided by the server.", "properties": { "encryption_method": { "const": "encrypted_verify_certificate", "default": "encrypted_verify_certificate", "enum": [ "encrypted_verify_certificate" ], "type": "string" }, "ssl_certificate": { "instillCredentialField": true, "description": "Privacy Enhanced Mail (PEM) files are concatenated certificate containers frequently used in certificate installations.", "multiline": true, "title": "SSL PEM file", "type": "string" } }, "required": [ "encryption_method", "ssl_certificate" ], "title": "TLS Encrypted (verify certificate)" } ], "order": 7, "title": "Encryption", "type": "object" }, "host": { "description": "The hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 5, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "The password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 1521, "description": "The port of the database.", "examples": [ "1521" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "default": "airbyte", "description": "The default schema is used as the target schema for all statements issued from the connection that do not explicitly specify a schema name. The usual value for this field is \"airbyte\". In Oracle, schemas and users are the same thing, so the \"user\" parameter is used as the login credentials and this is used for the default Airbyte message schema.", "examples": [ "airbyte" ], "order": 6, "title": "Default Schema", "type": "string" }, "sid": { "description": "The System Identifier uniquely distinguishes the instance from any other instance on the same computer.", "order": 2, "title": "SID", "type": "string" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "The username to access the database. This user must have CREATE USER privileges in the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "sid", "destination" ], "title": "Oracle", "type": "object" }, { "description": "The configuration model for the Vector DB based destinations. This model is used to generate the UI for the destination configuration,\nas well as to provide type safety for the configuration passed to the destination.\n\nThe configuration model is composed of four parts:\n* Processing configuration\n* Embedding configuration\n* Indexing configuration\n* Advanced configuration\n\nProcessing, embedding and advanced configuration are provided by this base class, while the indexing configuration is provided by the destination connector in the sub class.", "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "destination": { "const": "airbyte-destination-pinecone", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key", "mode" ], "title": "OpenAI", "type": "object" }, { "description": "Use the Cohere API to embed text.", "properties": { "cohere_key": { "instillCredentialField": true, "title": "Cohere API key", "type": "string" }, "mode": { "const": "cohere", "default": "cohere", "enum": [ "cohere" ], "title": "Mode", "type": "string" } }, "required": [ "cohere_key", "mode" ], "title": "Cohere", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "Fake", "type": "object" }, { "description": "Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "api_base": { "description": "The base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "https://your-resource-name.openai.azure.com" ], "title": "Resource base URL", "type": "string" }, "deployment": { "description": "The deployment for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "your-resource-name" ], "title": "Deployment", "type": "string" }, "mode": { "const": "azure_openai", "default": "azure_openai", "enum": [ "azure_openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "description": "The API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "title": "Azure OpenAI API key", "type": "string" } }, "required": [ "openai_key", "api_base", "deployment", "mode" ], "title": "Azure OpenAI", "type": "object" }, { "description": "Use a service that's compatible with the OpenAI API to embed text.", "properties": { "api_key": { "instillCredentialField": true, "default": "", "title": "API key", "type": "string" }, "base_url": { "description": "The base URL for your OpenAI-compatible service", "examples": [ "https://your-service-name.com" ], "title": "Base URL", "type": "string" }, "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "mode": { "const": "openai_compatible", "default": "openai_compatible", "enum": [ "openai_compatible" ], "title": "Mode", "type": "string" }, "model_name": { "default": "text-embedding-ada-002", "description": "The name of the model to use for embedding", "examples": [ "text-embedding-ada-002" ], "title": "Model name", "type": "string" } }, "required": [ "base_url", "dimensions", "mode" ], "title": "OpenAI-compatible", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Pinecone is a popular vector store that can be used to store and retrieve embeddings.", "group": "indexing", "properties": { "index": { "description": "Pinecone index in your project to load data into", "title": "Index", "type": "string" }, "pinecone_environment": { "description": "Pinecone Cloud environment to use", "examples": [ "us-west1-gcp", "gcp-starter" ], "title": "Pinecone Environment", "type": "string" }, "pinecone_key": { "instillCredentialField": true, "description": "The Pinecone API key to use matching the environment (copy from Pinecone console)", "title": "Pinecone API key", "type": "string" } }, "required": [ "pinecone_key", "pinecone_environment", "index" ], "title": "Indexing", "type": "object" }, "omit_raw_text": { "default": false, "description": "Do not store the text that gets embedded along with the vector and the metadata in the destination. If set to true, only the vector and the metadata will be stored - in this case raw text for LLM use cases needs to be retrieved from another source.", "group": "advanced", "title": "Do not store raw text", "type": "boolean" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "minimum": 1, "title": "Chunk size", "type": "integer" }, "field_name_mappings": { "default": [], "description": "List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation.", "items": { "properties": { "from_field": { "description": "The field name in the source", "title": "From field name", "type": "string" }, "to_field": { "description": "The field name to use in the destination", "title": "To field name", "type": "string" } }, "required": [ "from_field", "to_field" ], "title": "FieldNameMappingConfigModel", "type": "object" }, "title": "Field name mappings", "type": "array" }, "metadata_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path.", "examples": [ "age", "user", "user.name" ], "items": { "type": "string" }, "title": "Fields to store as metadata", "type": "array" }, "text_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" }, "text_splitter": { "description": "Split text fields into chunks based on the specified method.", "oneOf": [ { "description": "Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc.", "properties": { "keep_separator": { "default": false, "description": "Whether to keep the separator in the resulting chunks", "title": "Keep separator", "type": "boolean" }, "mode": { "const": "separator", "default": "separator", "enum": [ "separator" ], "title": "Mode", "type": "string" }, "separators": { "default": [ "\"\\n\\n\"", "\"\\n\"", "\" \"", "\"\"" ], "description": "List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \".\". To split by a newline, use \"\\n\".", "items": { "type": "string" }, "title": "Separators", "type": "array" } }, "required": [ "mode" ], "title": "By Separator", "type": "object" }, { "description": "Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk.", "properties": { "mode": { "const": "markdown", "default": "markdown", "enum": [ "markdown" ], "title": "Mode", "type": "string" }, "split_level": { "default": 1, "description": "Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points", "maximum": 6, "minimum": 1, "title": "Split level", "type": "integer" } }, "required": [ "mode" ], "title": "By Markdown header", "type": "object" }, { "description": "Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks.", "properties": { "language": { "description": "Split code in suitable places based on the programming language", "enum": [ "cpp", "go", "java", "js", "php", "proto", "python", "rst", "ruby", "rust", "scala", "swift", "markdown", "latex", "html", "sol" ], "title": "Language", "type": "string" }, "mode": { "const": "code", "default": "code", "enum": [ "code" ], "title": "Mode", "type": "string" } }, "required": [ "language", "mode" ], "title": "By Programming Language", "type": "object" } ], "title": "Text splitter", "type": "object" } }, "required": [ "chunk_size" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "embedding", "processing", "indexing", "destination" ], "title": "Pinecone", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-postgres", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 8, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 5, "title": "Password", "type": "string" }, "port": { "default": 5432, "description": "Port of the database.", "examples": [ "5432" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "default": "public", "description": "The default schema tables are written to if the source does not specify a namespace. The usual value for this field is \"public\".", "examples": [ "public" ], "order": 3, "title": "Default Schema", "type": "string" }, "ssl": { "default": false, "description": "Encrypt data using SSL. When activating SSL, please select one of the connection modes.", "order": 6, "title": "SSL Connection", "type": "boolean" }, "ssl_mode": { "description": "SSL connection modes. \n <b>disable</b> - Chose this mode to disable encryption of communication between Airbyte and destination database\n <b>allow</b> - Chose this mode to enable encryption only when required by the source database\n <b>prefer</b> - Chose this mode to allow unencrypted connection only if the source database does not support encryption\n <b>require</b> - Chose this mode to always require encryption. If the source database server does not support encryption, connection will fail\n <b>verify-ca</b> - Chose this mode to always require encryption and to verify that the source database server has a valid SSL certificate\n <b>verify-full</b> - This is the most secure mode. Chose this mode to always require encryption and to verify the identity of the source database server\n See more information - <a href=\"https://jdbc.postgresql.org/documentation/head/ssl-client.html\"> in the docs</a>.", "oneOf": [ { "additionalProperties": false, "description": "Disable SSL.", "properties": { "mode": { "const": "disable", "default": "disable", "enum": [ "disable" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "disable" }, { "additionalProperties": false, "description": "Allow SSL mode.", "properties": { "mode": { "const": "allow", "default": "allow", "enum": [ "allow" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "allow" }, { "additionalProperties": false, "description": "Prefer SSL mode.", "properties": { "mode": { "const": "prefer", "default": "prefer", "enum": [ "prefer" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "prefer" }, { "additionalProperties": false, "description": "Require SSL mode.", "properties": { "mode": { "const": "require", "default": "require", "enum": [ "require" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "require" }, { "additionalProperties": false, "description": "Verify-ca SSL mode.", "properties": { "ca_certificate": { "instillCredentialField": true, "description": "CA certificate", "multiline": true, "order": 1, "title": "CA certificate", "type": "string" }, "client_key_password": { "instillCredentialField": true, "description": "Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.", "order": 4, "title": "Client key password", "type": "string" }, "mode": { "const": "verify-ca", "default": "verify-ca", "enum": [ "verify-ca" ], "order": 0, "type": "string" } }, "required": [ "mode", "ca_certificate" ], "title": "verify-ca" }, { "additionalProperties": false, "description": "Verify-full SSL mode.", "properties": { "ca_certificate": { "instillCredentialField": true, "description": "CA certificate", "multiline": true, "order": 1, "title": "CA certificate", "type": "string" }, "client_certificate": { "instillCredentialField": true, "description": "Client certificate", "multiline": true, "order": 2, "title": "Client certificate", "type": "string" }, "client_key": { "instillCredentialField": true, "description": "Client key", "multiline": true, "order": 3, "title": "Client key", "type": "string" }, "client_key_password": { "instillCredentialField": true, "description": "Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.", "order": 4, "title": "Client key password", "type": "string" }, "mode": { "const": "verify-full", "default": "verify-full", "enum": [ "verify-full" ], "order": 0, "type": "string" } }, "required": [ "mode", "ca_certificate", "client_certificate", "client_key" ], "title": "verify-full" } ], "order": 7, "title": "SSL modes", "type": "object" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 4, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "database", "schema", "destination" ], "title": "Postgres", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "batching_delay_threshold": { "default": 1, "description": "Number of ms before the buffer is flushed", "minimum": 1, "title": "Message Batching: Delay Threshold", "type": "integer" }, "batching_element_count_threshold": { "default": 1, "description": "Number of messages before the buffer is flushed", "minimum": 1, "title": "Message Batching: Element Count Threshold", "type": "integer" }, "batching_enabled": { "default": false, "description": "If TRUE messages will be buffered instead of sending them one by one", "title": "Message Batching Enabled", "type": "boolean" }, "batching_request_bytes_threshold": { "default": 1, "description": "Number of bytes before the buffer is flushed", "minimum": 1, "title": "Message Batching: Request Bytes Threshold", "type": "integer" }, "credentials_json": { "instillCredentialField": true, "description": "The contents of the JSON service account key. Check out the <a href=\"https://docs.airbyte.com/integrations/destinations/pubsub\">docs</a> if you need help generating this key.", "title": "Credentials JSON", "type": "string" }, "destination": { "const": "airbyte-destination-pubsub", "type": "string" }, "ordering_enabled": { "default": false, "description": "If TRUE PubSub publisher will have <a href=\"https://cloud.google.com/pubsub/docs/ordering\">message ordering</a> enabled. Every message will have an ordering key of stream", "title": "Message Ordering Enabled", "type": "boolean" }, "project_id": { "description": "The GCP project ID for the project containing the target PubSub.", "title": "Project ID", "type": "string" }, "topic_id": { "description": "The PubSub topic ID in the given GCP project ID.", "title": "PubSub Topic ID", "type": "string" } }, "required": [ "project_id", "topic_id", "credentials_json", "ordering_enabled", "batching_enabled", "destination" ], "title": "Pubsub", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "batching_enabled": { "default": true, "description": "Control whether automatic batching of messages is enabled for the producer.", "title": "Enable batching", "type": "boolean" }, "batching_max_messages": { "default": 1000, "description": "Maximum number of messages permitted in a batch.", "title": "Batching max messages", "type": "integer" }, "batching_max_publish_delay": { "default": 1, "description": " Time period in milliseconds within which the messages sent will be batched.", "title": "Batching max publish delay", "type": "integer" }, "block_if_queue_full": { "default": false, "description": "If the send operation should block when the outgoing message queue is full.", "title": "Block if queue is full", "type": "boolean" }, "brokers": { "description": "A list of host/port pairs to use for establishing the initial connection to the Pulsar cluster.", "examples": [ "broker1:6650,broker2:6650" ], "title": "Pulsar brokers", "type": "string" }, "compression_type": { "default": "NONE", "description": "Compression type for the producer.", "enum": [ "NONE", "LZ4", "ZLIB", "ZSTD", "SNAPPY" ], "title": "Compression type", "type": "string" }, "destination": { "const": "airbyte-destination-pulsar", "type": "string" }, "max_pending_messages": { "default": 1000, "description": "The maximum size of a queue holding pending messages.", "title": "Max pending messages", "type": "integer" }, "max_pending_messages_across_partitions": { "default": 50000, "description": "The maximum number of pending messages across partitions.", "title": "Max pending messages across partitions", "type": "integer" }, "producer_name": { "description": "Name for the producer. If not filled, the system will generate a globally unique name which can be accessed with.", "examples": [ "airbyte-producer" ], "title": "Producer name", "type": "string" }, "producer_sync": { "default": false, "description": "Wait synchronously until the record has been sent to Pulsar.", "title": "Sync producer", "type": "boolean" }, "send_timeout_ms": { "default": 30000, "description": "If a message is not acknowledged by a server before the send-timeout expires, an error occurs (in ms).", "title": "Message send timeout", "type": "integer" }, "topic_namespace": { "default": "default", "description": "The administrative unit of the topic, which acts as a grouping mechanism for related topics. Most topic configuration is performed at the namespace level. Each tenant has one or multiple namespaces.", "examples": [ "default" ], "title": "Topic namespace", "type": "string" }, "topic_pattern": { "description": "Topic pattern in which the records will be sent. You can use patterns like '{namespace}' and/or '{stream}' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention.", "examples": [ "sample.topic", "{namespace}.{stream}.sample" ], "title": "Topic pattern", "type": "string" }, "topic_tenant": { "default": "public", "description": "The topic tenant within the instance. Tenants are essential to multi-tenancy in Pulsar, and spread across clusters.", "examples": [ "public" ], "title": "Topic tenant", "type": "string" }, "topic_test": { "description": "Topic to test if Airbyte can produce messages.", "examples": [ "test.topic" ], "title": "Test topic", "type": "string" }, "topic_type": { "default": "persistent", "description": "It identifies type of topic. Pulsar supports two kind of topics: persistent and non-persistent. In persistent topic, all messages are durably persisted on disk (that means on multiple disks unless the broker is standalone), whereas non-persistent topic does not persist message into storage disk.", "enum": [ "persistent", "non-persistent" ], "title": "Topic type", "type": "string" }, "use_tls": { "default": false, "description": "Whether to use TLS encryption on the connection.", "title": "Use TLS", "type": "boolean" } }, "required": [ "brokers", "use_tls", "topic_type", "topic_tenant", "topic_namespace", "topic_pattern", "compression_type", "send_timeout_ms", "max_pending_messages", "max_pending_messages_across_partitions", "batching_enabled", "batching_max_messages", "batching_max_publish_delay", "block_if_queue_full", "destination" ], "title": "Pulsar", "type": "object" }, { "description": "The configuration model for the Vector DB based destinations. This model is used to generate the UI for the destination configuration,\nas well as to provide type safety for the configuration passed to the destination.\n\nThe configuration model is composed of four parts:\n* Processing configuration\n* Embedding configuration\n* Indexing configuration\n* Advanced configuration\n\nProcessing, embedding and advanced configuration are provided by this base class, while the indexing configuration is provided by the destination connector in the sub class.", "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "destination": { "const": "airbyte-destination-qdrant", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key", "mode" ], "title": "OpenAI", "type": "object" }, { "description": "Use the Cohere API to embed text.", "properties": { "cohere_key": { "instillCredentialField": true, "title": "Cohere API key", "type": "string" }, "mode": { "const": "cohere", "default": "cohere", "enum": [ "cohere" ], "title": "Mode", "type": "string" } }, "required": [ "cohere_key", "mode" ], "title": "Cohere", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "Fake", "type": "object" }, { "description": "Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "api_base": { "description": "The base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "https://your-resource-name.openai.azure.com" ], "title": "Resource base URL", "type": "string" }, "deployment": { "description": "The deployment for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "your-resource-name" ], "title": "Deployment", "type": "string" }, "mode": { "const": "azure_openai", "default": "azure_openai", "enum": [ "azure_openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "description": "The API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "title": "Azure OpenAI API key", "type": "string" } }, "required": [ "openai_key", "api_base", "deployment", "mode" ], "title": "Azure OpenAI", "type": "object" }, { "description": "Use a service that's compatible with the OpenAI API to embed text.", "properties": { "api_key": { "instillCredentialField": true, "default": "", "title": "API key", "type": "string" }, "base_url": { "description": "The base URL for your OpenAI-compatible service", "examples": [ "https://your-service-name.com" ], "title": "Base URL", "type": "string" }, "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "mode": { "const": "openai_compatible", "default": "openai_compatible", "enum": [ "openai_compatible" ], "title": "Mode", "type": "string" }, "model_name": { "default": "text-embedding-ada-002", "description": "The name of the model to use for embedding", "examples": [ "text-embedding-ada-002" ], "title": "Model name", "type": "string" } }, "required": [ "base_url", "dimensions", "mode" ], "title": "OpenAI-compatible", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Indexing configuration", "group": "Indexing", "properties": { "auth_method": { "default": "api_key_auth", "description": "Method to authenticate with the Qdrant Instance", "oneOf": [ { "properties": { "api_key": { "instillCredentialField": true, "description": "API Key for the Qdrant instance", "title": "API Key", "type": "string" }, "mode": { "const": "api_key_auth", "default": "api_key_auth", "enum": [ "api_key_auth" ], "title": "Mode", "type": "string" } }, "required": [ "api_key" ], "title": "ApiKeyAuth", "type": "object" }, { "properties": { "mode": { "const": "no_auth", "default": "no_auth", "enum": [ "no_auth" ], "title": "Mode", "type": "string" } }, "title": "NoAuth", "type": "object" } ], "order": 1, "title": "Authentication Method", "type": "object" }, "collection": { "description": "The collection to load data into", "order": 2, "title": "Collection Name", "type": "string" }, "distance_metric": { "default": "cos", "description": "The Distance metric used to measure similarities among vectors. This field is only used if the collection defined in the does not exist yet and is created automatically by the connector.", "enum": [ "dot", "cos", "euc" ], "title": "Distance Metric", "type": "string" }, "prefer_grpc": { "default": true, "description": "Whether to prefer gRPC over HTTP. Set to true for Qdrant cloud clusters", "title": "Prefer gRPC", "type": "boolean" }, "text_field": { "default": "text", "description": "The field in the payload that contains the embedded text", "title": "Text Field", "type": "string" }, "url": { "description": "Public Endpoint of the Qdrant cluser", "order": 0, "title": "Public Endpoint", "type": "string" } }, "required": [ "url", "collection" ], "title": "Indexing", "type": "object" }, "omit_raw_text": { "default": false, "description": "Do not store the text that gets embedded along with the vector and the metadata in the destination. If set to true, only the vector and the metadata will be stored - in this case raw text for LLM use cases needs to be retrieved from another source.", "group": "advanced", "title": "Do not store raw text", "type": "boolean" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "minimum": 1, "title": "Chunk size", "type": "integer" }, "field_name_mappings": { "default": [], "description": "List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation.", "items": { "properties": { "from_field": { "description": "The field name in the source", "title": "From field name", "type": "string" }, "to_field": { "description": "The field name to use in the destination", "title": "To field name", "type": "string" } }, "required": [ "from_field", "to_field" ], "title": "FieldNameMappingConfigModel", "type": "object" }, "title": "Field name mappings", "type": "array" }, "metadata_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path.", "examples": [ "age", "user", "user.name" ], "items": { "type": "string" }, "title": "Fields to store as metadata", "type": "array" }, "text_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" }, "text_splitter": { "description": "Split text fields into chunks based on the specified method.", "oneOf": [ { "description": "Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc.", "properties": { "keep_separator": { "default": false, "description": "Whether to keep the separator in the resulting chunks", "title": "Keep separator", "type": "boolean" }, "mode": { "const": "separator", "default": "separator", "enum": [ "separator" ], "title": "Mode", "type": "string" }, "separators": { "default": [ "\"\\n\\n\"", "\"\\n\"", "\" \"", "\"\"" ], "description": "List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \".\". To split by a newline, use \"\\n\".", "items": { "type": "string" }, "title": "Separators", "type": "array" } }, "required": [ "mode" ], "title": "By Separator", "type": "object" }, { "description": "Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk.", "properties": { "mode": { "const": "markdown", "default": "markdown", "enum": [ "markdown" ], "title": "Mode", "type": "string" }, "split_level": { "default": 1, "description": "Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points", "maximum": 6, "minimum": 1, "title": "Split level", "type": "integer" } }, "required": [ "mode" ], "title": "By Markdown header", "type": "object" }, { "description": "Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks.", "properties": { "language": { "description": "Split code in suitable places based on the programming language", "enum": [ "cpp", "go", "java", "js", "php", "proto", "python", "rst", "ruby", "rust", "scala", "swift", "markdown", "latex", "html", "sol" ], "title": "Language", "type": "string" }, "mode": { "const": "code", "default": "code", "enum": [ "code" ], "title": "Mode", "type": "string" } }, "required": [ "language", "mode" ], "title": "By Programming Language", "type": "object" } ], "title": "Text splitter", "type": "object" } }, "required": [ "chunk_size" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "embedding", "processing", "indexing", "destination" ], "title": "Qdrant", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "access_key_id": { "instillCredentialField": true, "description": "The access key ID to access the R2 bucket. Airbyte requires Read and Write permissions to the given bucket. Read more <a href=\"https://developers.cloudflare.com/r2/platform/s3-compatibility/tokens/\">here</a>.", "examples": [ "A012345678910EXAMPLE" ], "order": 1, "title": "R2 Key ID *", "type": "string" }, "account_id": { "description": "Cloudflare account ID", "examples": [ "12345678aa1a1a11111aaa1234567abc" ], "order": 0, "title": "Cloudflare account ID", "type": "string" }, "destination": { "const": "airbyte-destination-r2", "type": "string" }, "file_name_pattern": { "description": "The pattern allows you to set the file-name format for the R2 staging file(s)", "examples": [ "{date}", "{date:yyyy_MM}", "{timestamp}", "{part_number}", "{sync_id}" ], "order": 7, "title": "R2 Filename pattern (Optional)", "type": "string" }, "format": { "description": "Format of the data output. See <a href=\"https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema\">here</a> for more details", "oneOf": [ { "properties": { "compression_codec": { "description": "The compression algorithm used to compress data. Default to no compression.", "oneOf": [ { "properties": { "codec": { "default": "no compression", "enum": [ "no compression" ], "type": "string" } }, "required": [ "codec" ], "title": "No Compression" }, { "properties": { "codec": { "default": "Deflate", "enum": [ "Deflate" ], "type": "string" }, "compression_level": { "default": 0, "description": "0: no compression & fastest, 9: best compression & slowest.", "maximum": 9, "minimum": 0, "title": "Deflate Level", "type": "integer" } }, "required": [ "codec", "compression_level" ], "title": "Deflate" }, { "properties": { "codec": { "default": "bzip2", "enum": [ "bzip2" ], "type": "string" } }, "required": [ "codec" ], "title": "bzip2" }, { "properties": { "codec": { "default": "xz", "enum": [ "xz" ], "type": "string" }, "compression_level": { "default": 6, "description": "See <a href=\"https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-\">here</a> for details.", "maximum": 9, "minimum": 0, "title": "Compression Level", "type": "integer" } }, "required": [ "codec", "compression_level" ], "title": "xz" }, { "properties": { "codec": { "default": "zstandard", "enum": [ "zstandard" ], "type": "string" }, "compression_level": { "default": 3, "description": "Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.", "maximum": 22, "minimum": -5, "title": "Compression Level", "type": "integer" }, "include_checksum": { "default": false, "description": "If true, include a checksum with each data block.", "title": "Include Checksum", "type": "boolean" } }, "required": [ "codec", "compression_level" ], "title": "zstandard" }, { "properties": { "codec": { "default": "snappy", "enum": [ "snappy" ], "type": "string" } }, "required": [ "codec" ], "title": "snappy" } ], "order": 1, "title": "Compression Codec *", "type": "object" }, "format_type": { "default": "Avro", "enum": [ "Avro" ], "order": 0, "title": "Format Type *", "type": "string" } }, "required": [ "format_type", "compression_codec" ], "title": "Avro: Apache Avro" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".csv.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "GZIP" } ], "title": "Compression", "type": "object" }, "flattening": { "default": "No flattening", "description": "Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Normalization (Flattening)", "type": "string" }, "format_type": { "default": "CSV", "enum": [ "CSV" ], "title": "Format Type *", "type": "string" } }, "required": [ "format_type", "flattening" ], "title": "CSV: Comma-Separated Values" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".jsonl.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": "compression_type", "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": "compression_type", "title": "GZIP" } ], "title": "Compression", "type": "object" }, "format_type": { "default": "JSONL", "enum": [ "JSONL" ], "title": "Format Type *", "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: Newline-delimited JSON" } ], "order": 5, "title": "Output Format *", "type": "object" }, "s3_bucket_name": { "description": "The name of the R2 bucket. Read more <a href=\"https://developers.cloudflare.com/r2/get-started/#3-create-your-bucket\">here</a>.", "examples": [ "r2_sync" ], "order": 3, "title": "R2 Bucket Name", "type": "string" }, "s3_bucket_path": { "description": "Directory under the R2 bucket where data will be written.", "examples": [ "data_sync/test" ], "order": 4, "title": "R2 Bucket Path", "type": "string" }, "s3_path_format": { "description": "Format string on how data will be organized inside the R2 bucket directory. Read more <a href=\"https://docs.airbyte.com/integrations/destinations/r2#:~:text=The%20full%20path%20of%20the%20output%20data%20with%20the%20default%20S3%20path%20format\">here</a>", "examples": [ "${NAMESPACE}/${STREAM_NAME}/${YEAR}_${MONTH}_${DAY}_${EPOCH}_" ], "order": 6, "title": "R2 Path Format (Optional)", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the access key ID. Read more <a href=\"https://developers.cloudflare.com/r2/platform/s3-compatibility/tokens/\">here</a>", "examples": [ "a012345678910ABCDEFGHAbCdEfGhEXAMPLEKEY" ], "order": 2, "title": "R2 Access Key *", "type": "string" } }, "required": [ "account_id", "access_key_id", "secret_access_key", "s3_bucket_name", "s3_bucket_path", "format", "destination" ], "title": "R2", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "destination": { "const": "airbyte-destination-rabbitmq", "type": "string" }, "exchange": { "description": "The exchange name.", "type": "string" }, "host": { "description": "The RabbitMQ host name.", "type": "string" }, "password": { "instillCredentialField": true, "description": "The password to connect.", "title": "Password", "type": "string" }, "port": { "description": "The RabbitMQ port.", "type": "integer" }, "routing_key": { "description": "The routing key.", "type": "string" }, "ssl": { "default": true, "description": "SSL enabled.", "type": "boolean" }, "username": { "description": "The username to connect.", "type": "string" }, "virtual_host": { "description": "The RabbitMQ virtual host name.", "type": "string" } }, "required": [ "host", "routing_key", "destination" ], "title": "Rabbitmq", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "cache_type": { "default": "hash", "description": "Redis cache type to store data in.", "enum": [ "hash" ], "order": 7, "title": "Cache type", "type": "string" }, "destination": { "const": "airbyte-destination-redis", "type": "string" }, "host": { "description": "Redis host to connect to.", "examples": [ "localhost,127.0.0.1" ], "order": 1, "title": "Host", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with Redis.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 6379, "description": "Port of Redis.", "maximum": 65536, "minimum": 0, "order": 2, "title": "Port", "type": "integer" }, "ssl": { "default": false, "description": "Indicates whether SSL encryption protocol will be used to connect to Redis. It is recommended to use SSL connection if possible.", "order": 5, "title": "SSL Connection", "type": "boolean" }, "ssl_mode": { "description": "SSL connection modes. \n <li><b>verify-full</b> - This is the most secure mode. Always require encryption and verifies the identity of the source database server", "oneOf": [ { "additionalProperties": false, "description": "Disable SSL.", "properties": { "mode": { "const": "disable", "default": "disable", "enum": [ "disable" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "disable" }, { "additionalProperties": false, "description": "Verify-full SSL mode.", "properties": { "ca_certificate": { "instillCredentialField": true, "description": "CA certificate", "multiline": true, "order": 1, "title": "CA Certificate", "type": "string" }, "client_certificate": { "instillCredentialField": true, "description": "Client certificate", "multiline": true, "order": 2, "title": "Client Certificate", "type": "string" }, "client_key": { "instillCredentialField": true, "description": "Client key", "multiline": true, "order": 3, "title": "Client Key", "type": "string" }, "client_key_password": { "instillCredentialField": true, "description": "Password for keystorage. If you do not add it - the password will be generated automatically.", "order": 4, "title": "Client key password", "type": "string" }, "mode": { "const": "verify-full", "default": "verify-full", "enum": [ "verify-full" ], "order": 0, "type": "string" } }, "required": [ "mode", "ca_certificate", "client_certificate", "client_key" ], "title": "verify-full" } ], "order": 6, "title": "SSL Modes", "type": "object" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username associated with Redis.", "order": 3, "title": "Username", "type": "string" } }, "required": [ "host", "username", "port", "cache_type", "destination" ], "title": "Redis", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "batch_size": { "description": "The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.", "examples": [ 16384 ], "title": "Batch Size", "type": "integer" }, "bootstrap_servers": { "description": "A list of host/port pairs to use for establishing the initial connection to the Redpanda cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).", "examples": [ "redpanda-broker1:9092,redpanda-broker2:9092" ], "title": "Bootstrap Servers", "type": "string" }, "buffer_memory": { "description": "The total bytes of memory the producer can use to buffer records waiting to be sent to the server.", "examples": 33554432, "title": "Buffer Memory", "type": "string" }, "compression_type": { "default": "none", "description": "The compression type for all data generated by the producer.", "enum": [ "none", "gzip", "snappy", "lz4", "zstd" ], "title": "Compression Type", "type": "string" }, "destination": { "const": "airbyte-destination-redpanda", "type": "string" }, "retries": { "description": "Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.", "examples": [ 2147483647 ], "title": "Retries", "type": "integer" }, "socket_connection_setup_timeout_max_ms": { "description": "The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum.", "examples": [ 30000 ], "title": "Socket Connection Setup Max Timeout", "type": "integer" }, "socket_connection_setup_timeout_ms": { "description": "The amount of time the client will wait for the socket connection to be established.", "examples": [ 10000 ], "title": "Socket Connection Setup Timeout", "type": "integer" }, "topic_num_partitions": { "description": "The number of topic partitions which will be created on topic creation", "examples": [ 10 ], "title": "Number of topic partitions", "type": "integer" }, "topic_replication_factor": { "description": "The number of topics to which messages will be replicated", "examples": [ 10 ], "title": "Topic replication factor", "type": "integer" } }, "required": [ "bootstrap_servers", "buffer_memory", "compression_type", "retries", "batch_size", "destination" ], "title": "Redpanda", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "groups": [ { "id": "connection", "title": "Connection" } ], "properties": { "database": { "description": "Name of the database.", "group": "connection", "order": 5, "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-redshift", "type": "string" }, "host": { "description": "Host Endpoint of the Redshift Cluster (must include the cluster-id, region and end with .redshift.amazonaws.com)", "group": "connection", "order": 1, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "group": "connection", "order": 7, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "group": "connection", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 5439, "description": "Port of the database.", "examples": [ "5439" ], "group": "connection", "maximum": 65536, "minimum": 0, "order": 2, "title": "Port", "type": "integer" }, "raw_data_schema": { "description": "(Early Access) The schema to write raw tables into", "order": 10, "title": "Destinations V2 Raw Table Schema (Early Access)", "type": "string" }, "schema": { "default": "public", "description": "The default schema tables are written to if the source does not specify a namespace. Unless specifically configured, the usual value for this field is \"public\".", "examples": [ "public" ], "group": "connection", "order": 6, "title": "Default Schema", "type": "string" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "uploading_method": { "description": "The way data will be uploaded to Redshift.", "display_type": "radio", "group": "connection", "oneOf": [ { "description": "<i>(recommended)</i> Uploads data to S3 and then uses a COPY to insert the data into Redshift. COPY is recommended for production workloads for better speed and scalability. See <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html\">AWS docs</a> for more details.", "properties": { "access_key_id": { "instillCredentialField": true, "description": "This ID grants access to the above S3 staging bucket. Airbyte requires Read and Write permissions to the given bucket. See <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">AWS docs</a> on how to generate an access key ID and secret access key.", "order": 3, "title": "S3 Access Key Id", "type": "string" }, "encryption": { "default": { "encryption_type": "none" }, "description": "How to encrypt the staging data", "oneOf": [ { "description": "Staging data will be stored in plaintext.", "properties": { "encryption_type": { "const": "none", "default": "none", "enum": [ "none" ], "type": "string" } }, "required": [ "encryption_type" ], "title": "No encryption", "type": "object" }, { "description": "Staging data will be encrypted using AES-CBC envelope encryption.", "properties": { "encryption_type": { "const": "aes_cbc_envelope", "default": "aes_cbc_envelope", "enum": [ "aes_cbc_envelope" ], "type": "string" }, "key_encrypting_key": { "instillCredentialField": true, "description": "The key, base64-encoded. Must be either 128, 192, or 256 bits. Leave blank to have Airbyte generate an ephemeral key for each sync.", "title": "Key", "type": "string" } }, "required": [ "encryption_type" ], "title": "AES-CBC envelope encryption", "type": "object" } ], "order": 7, "title": "Encryption", "type": "object" }, "file_buffer_count": { "default": 10, "description": "Number of file buffers allocated for writing data. Increasing this number is beneficial for connections using Change Data Capture (CDC) and up to the number of streams within a connection. Increasing the number of file buffers past the maximum number of streams has deteriorating effects", "examples": [ "10" ], "maximum": 50, "minimum": 10, "title": "File Buffer Count", "type": "integer" }, "file_name_pattern": { "description": "The pattern allows you to set the file-name format for the S3 staging file(s)", "examples": [ "{date}", "{date:yyyy_MM}", "{timestamp}", "{part_number}", "{sync_id}" ], "order": 5, "title": "S3 Filename pattern", "type": "string" }, "method": { "const": "S3 Staging", "type": "string" }, "purge_staging_data": { "default": true, "description": "Whether to delete the staging files from S3 after completing the sync. See <a href=\"https://docs.airbyte.com/integrations/destinations/redshift/#:~:text=the%20root%20directory.-,Purge%20Staging%20Data,-Whether%20to%20delete\"> docs</a> for details.", "order": 6, "title": "Purge Staging Files and Tables", "type": "boolean" }, "s3_bucket_name": { "description": "The name of the staging S3 bucket.", "examples": [ "airbyte.staging" ], "order": 0, "title": "S3 Bucket Name", "type": "string" }, "s3_bucket_path": { "description": "The directory under the S3 bucket where data will be written. If not provided, then defaults to the root directory. See <a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/defining-bucket-names-data-lakes/faq.html#:~:text=be%20globally%20unique.-,For%20S3%20bucket%20paths,-%2C%20you%20can%20use\">path's name recommendations</a> for more details.", "examples": [ "data_sync/test" ], "order": 1, "title": "S3 Bucket Path", "type": "string" }, "s3_bucket_region": { "default": "", "description": "The region of the S3 staging bucket.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1" ], "order": 2, "title": "S3 Bucket Region", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the above access key id. See <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">AWS docs</a> on how to generate an access key ID and secret access key.", "order": 4, "title": "S3 Secret Access Key", "type": "string" } }, "required": [ "method", "s3_bucket_name", "s3_bucket_region", "access_key_id", "secret_access_key" ], "title": "AWS S3 Staging" }, { "description": "<i>(not recommended)</i> Direct loading using SQL INSERT statements. This method is extremely inefficient and provided only for quick testing. In all other cases, you should use S3 uploading.", "properties": { "method": { "const": "Standard", "type": "string" } }, "required": [ "method" ], "title": "Standard" } ], "order": 8, "title": "Uploading Method", "type": "object" }, "use_1s1t_format": { "description": "(Early Access) Use <a href=\"https://docs.airbyte.com/understanding-airbyte/typing-deduping\" target=\"_blank\">Destinations V2</a>.", "order": 9, "title": "Use Destinations V2 (Early Access)", "type": "boolean" }, "username": { "description": "Username to use to access the database.", "group": "connection", "order": 3, "title": "Username", "type": "string" } }, "required": [ "host", "port", "database", "username", "password", "schema", "destination" ], "title": "Redshift", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "api_key": { "instillCredentialField": true, "description": "Rockset api key", "order": 0, "title": "Api Key", "type": "string" }, "api_server": { "instillCredentialField": false, "default": "https://api.rs2.usw2.rockset.com", "description": "Rockset api URL", "order": 2, "pattern": "^https:\\/\\/.*.rockset.com$", "title": "Api Server", "type": "string" }, "destination": { "const": "airbyte-destination-rockset", "type": "string" }, "workspace": { "instillCredentialField": false, "default": "commons", "description": "The Rockset workspace in which collections will be created + written to.", "examples": [ "commons", "my_workspace" ], "order": 1, "title": "Workspace", "type": "string" } }, "required": [ "api_key", "workspace", "destination" ], "title": "Rockset", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "access_key_id": { "instillCredentialField": true, "description": "The access key ID to access the S3 bucket. Airbyte requires Read and Write permissions to the given bucket. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>.", "examples": [ "A012345678910EXAMPLE" ], "order": 0, "title": "S3 Key ID", "type": "string" }, "destination": { "const": "airbyte-destination-s3-glue", "type": "string" }, "file_name_pattern": { "description": "The pattern allows you to set the file-name format for the S3 staging file(s)", "examples": [ "{date}", "{date:yyyy_MM}", "{timestamp}", "{part_number}", "{sync_id}" ], "order": 8, "title": "S3 Filename pattern", "type": "string" }, "format": { "description": "Format of the data output. See <a href=\"https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema\">here</a> for more details", "oneOf": [ { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".jsonl.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": "compression_type", "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": "compression_type", "title": "GZIP" } ], "title": "Compression", "type": "object" }, "flattening": { "default": "Root level flattening", "description": "Whether the input json data should be normalized (flattened) in the output JSON Lines. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Flattening", "type": "string" }, "format_type": { "default": "JSONL", "enum": [ "JSONL" ], "title": "Format Type", "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: Newline-delimited JSON" } ], "order": 5, "title": "Output Format", "type": "object" }, "glue_database": { "description": "Name of the glue database for creating the tables, leave blank if no integration", "examples": [ "airbyte_database" ], "order": 9, "title": "Glue database name", "type": "string" }, "glue_serialization_library": { "default": "org.openx.data.jsonserde.JsonSerDe", "description": "The library that your query engine will use for reading and writing data in your lake.", "enum": [ "org.openx.data.jsonserde.JsonSerDe", "org.apache.hive.hcatalog.data.JsonSerDe" ], "order": 10, "title": "Serialization Library", "type": "string" }, "s3_bucket_name": { "description": "The name of the S3 bucket. Read more <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html\">here</a>.", "examples": [ "airbyte_sync" ], "order": 2, "title": "S3 Bucket Name", "type": "string" }, "s3_bucket_path": { "description": "Directory under the S3 bucket where data will be written. Read more <a href=\"https://docs.airbyte.com/integrations/destinations/s3#:~:text=to%20format%20the-,bucket%20path,-%3A\">here</a>", "examples": [ "data_sync/test" ], "order": 3, "title": "S3 Bucket Path", "type": "string" }, "s3_bucket_region": { "default": "", "description": "The region of the S3 bucket. See <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions\">here</a> for all region codes.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 4, "title": "S3 Bucket Region", "type": "string" }, "s3_endpoint": { "default": "", "description": "Your S3 endpoint url. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/s3.html#:~:text=Service%20endpoints-,Amazon%20S3%20endpoints,-When%20you%20use\">here</a>", "examples": [ "http://localhost:9000" ], "order": 6, "title": "Endpoint", "type": "string" }, "s3_path_format": { "description": "Format string on how data will be organized inside the S3 bucket directory. Read more <a href=\"https://docs.airbyte.com/integrations/destinations/s3#:~:text=The%20full%20path%20of%20the%20output%20data%20with%20the%20default%20S3%20path%20format\">here</a>", "examples": [ "${NAMESPACE}/${STREAM_NAME}/${YEAR}_${MONTH}_${DAY}_${EPOCH}_" ], "order": 7, "title": "S3 Path Format", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the access key ID. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "order": 1, "title": "S3 Access Key", "type": "string" } }, "required": [ "s3_bucket_name", "s3_bucket_path", "s3_bucket_region", "format", "glue_database", "glue_serialization_library", "destination" ], "title": "S3glue", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "access_key_id": { "instillCredentialField": true, "description": "The access key ID to access the S3 bucket. Airbyte requires Read and Write permissions to the given bucket. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>.", "examples": [ "A012345678910EXAMPLE" ], "order": 0, "title": "S3 Key ID", "type": "string" }, "destination": { "const": "airbyte-destination-s3", "type": "string" }, "file_name_pattern": { "description": "The pattern allows you to set the file-name format for the S3 staging file(s)", "examples": [ "{date}", "{date:yyyy_MM}", "{timestamp}", "{part_number}", "{sync_id}" ], "order": 8, "title": "S3 Filename pattern", "type": "string" }, "format": { "description": "Format of the data output. See <a href=\"https://docs.airbyte.com/integrations/destinations/s3/#supported-output-schema\">here</a> for more details", "oneOf": [ { "properties": { "compression_codec": { "description": "The compression algorithm used to compress data. Default to no compression.", "oneOf": [ { "properties": { "codec": { "default": "no compression", "enum": [ "no compression" ], "type": "string" } }, "required": [ "codec" ], "title": "No Compression" }, { "properties": { "codec": { "default": "Deflate", "enum": [ "Deflate" ], "type": "string" }, "compression_level": { "default": 0, "description": "0: no compression & fastest, 9: best compression & slowest.", "maximum": 9, "minimum": 0, "title": "Deflate Level", "type": "integer" } }, "required": [ "codec", "compression_level" ], "title": "Deflate" }, { "properties": { "codec": { "default": "bzip2", "enum": [ "bzip2" ], "type": "string" } }, "required": [ "codec" ], "title": "bzip2" }, { "properties": { "codec": { "default": "xz", "enum": [ "xz" ], "type": "string" }, "compression_level": { "default": 6, "description": "See <a href=\"https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-\">here</a> for details.", "maximum": 9, "minimum": 0, "title": "Compression Level", "type": "integer" } }, "required": [ "codec", "compression_level" ], "title": "xz" }, { "properties": { "codec": { "default": "zstandard", "enum": [ "zstandard" ], "type": "string" }, "compression_level": { "default": 3, "description": "Negative levels are 'fast' modes akin to lz4 or snappy, levels above 9 are generally for archival purposes, and levels above 18 use a lot of memory.", "maximum": 22, "minimum": -5, "title": "Compression Level", "type": "integer" }, "include_checksum": { "default": false, "description": "If true, include a checksum with each data block.", "title": "Include Checksum", "type": "boolean" } }, "required": [ "codec", "compression_level" ], "title": "zstandard" }, { "properties": { "codec": { "default": "snappy", "enum": [ "snappy" ], "type": "string" } }, "required": [ "codec" ], "title": "snappy" } ], "order": 1, "title": "Compression Codec", "type": "object" }, "format_type": { "default": "Avro", "enum": [ "Avro" ], "order": 0, "title": "Format Type", "type": "string" } }, "required": [ "format_type", "compression_codec" ], "title": "Avro: Apache Avro" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".csv.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": [ "compression_type" ], "title": "GZIP" } ], "title": "Compression", "type": "object" }, "flattening": { "default": "No flattening", "description": "Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Flattening", "type": "string" }, "format_type": { "default": "CSV", "enum": [ "CSV" ], "title": "Format Type", "type": "string" } }, "required": [ "format_type", "flattening" ], "title": "CSV: Comma-Separated Values" }, { "properties": { "compression": { "description": "Whether the output files should be compressed. If compression is selected, the output filename will have an extra extension (GZIP: \".jsonl.gz\").", "oneOf": [ { "properties": { "compression_type": { "default": "No Compression", "enum": [ "No Compression" ], "type": "string" } }, "requires": "compression_type", "title": "No Compression" }, { "properties": { "compression_type": { "default": "GZIP", "enum": [ "GZIP" ], "type": "string" } }, "requires": "compression_type", "title": "GZIP" } ], "title": "Compression", "type": "object" }, "flattening": { "default": "No flattening", "description": "Whether the input json data should be normalized (flattened) in the output JSON Lines. Please refer to docs for details.", "enum": [ "No flattening", "Root level flattening" ], "title": "Flattening", "type": "string" }, "format_type": { "default": "JSONL", "enum": [ "JSONL" ], "title": "Format Type", "type": "string" } }, "required": [ "format_type" ], "title": "JSON Lines: Newline-delimited JSON" }, { "properties": { "block_size_mb": { "default": 128, "description": "This is the size of a row group being buffered in memory. It limits the memory usage when writing. Larger values will improve the IO when reading, but consume more memory when writing. Default: 128 MB.", "examples": [ 128 ], "title": "Block Size (Row Group Size) (MB)", "type": "integer" }, "compression_codec": { "default": "UNCOMPRESSED", "description": "The compression algorithm used to compress data pages.", "enum": [ "UNCOMPRESSED", "SNAPPY", "GZIP", "LZO", "BROTLI", "LZ4", "ZSTD" ], "title": "Compression Codec", "type": "string" }, "dictionary_encoding": { "default": true, "description": "Default: true.", "title": "Dictionary Encoding", "type": "boolean" }, "dictionary_page_size_kb": { "default": 1024, "description": "There is one dictionary page per column per row group when dictionary encoding is used. The dictionary page size works like the page size but for dictionary. Default: 1024 KB.", "examples": [ 1024 ], "title": "Dictionary Page Size (KB)", "type": "integer" }, "format_type": { "default": "Parquet", "enum": [ "Parquet" ], "title": "Format Type", "type": "string" }, "max_padding_size_mb": { "default": 8, "description": "Maximum size allowed as padding to align row groups. This is also the minimum size of a row group. Default: 8 MB.", "examples": [ 8 ], "title": "Max Padding Size (MB)", "type": "integer" }, "page_size_kb": { "default": 1024, "description": "The page size is for compression. A block is composed of pages. A page is the smallest unit that must be read fully to access a single record. If this value is too small, the compression will deteriorate. Default: 1024 KB.", "examples": [ 1024 ], "title": "Page Size (KB)", "type": "integer" } }, "required": [ "format_type" ], "title": "Parquet: Columnar Storage" } ], "order": 5, "title": "Output Format", "type": "object" }, "s3_bucket_name": { "description": "The name of the S3 bucket. Read more <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html\">here</a>.", "examples": [ "airbyte_sync" ], "order": 2, "title": "S3 Bucket Name", "type": "string" }, "s3_bucket_path": { "description": "Directory under the S3 bucket where data will be written. Read more <a href=\"https://docs.airbyte.com/integrations/destinations/s3#:~:text=to%20format%20the-,bucket%20path,-%3A\">here</a>", "examples": [ "data_sync/test" ], "order": 3, "title": "S3 Bucket Path", "type": "string" }, "s3_bucket_region": { "default": "", "description": "The region of the S3 bucket. See <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions\">here</a> for all region codes.", "enum": [ "", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1" ], "order": 4, "title": "S3 Bucket Region", "type": "string" }, "s3_endpoint": { "default": "", "description": "Your S3 endpoint url. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/s3.html#:~:text=Service%20endpoints-,Amazon%20S3%20endpoints,-When%20you%20use\">here</a>", "examples": [ "http://localhost:9000" ], "order": 6, "title": "Endpoint", "type": "string" }, "s3_path_format": { "description": "Format string on how data will be organized inside the S3 bucket directory. Read more <a href=\"https://docs.airbyte.com/integrations/destinations/s3#:~:text=The%20full%20path%20of%20the%20output%20data%20with%20the%20default%20S3%20path%20format\">here</a>", "examples": [ "${NAMESPACE}/${STREAM_NAME}/${YEAR}_${MONTH}_${DAY}_${EPOCH}_" ], "order": 7, "title": "S3 Path Format", "type": "string" }, "secret_access_key": { "instillCredentialField": true, "description": "The corresponding secret to the access key ID. Read more <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\">here</a>", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "order": 1, "title": "S3 Access Key", "type": "string" } }, "required": [ "s3_bucket_name", "s3_bucket_path", "s3_bucket_region", "format", "destination" ], "title": "S3", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "address": { "description": "Address to connect to.", "order": 3, "title": "Address", "type": "string" }, "destination": { "const": "airbyte-destination-scylla", "type": "string" }, "keyspace": { "description": "Default Scylla keyspace to create data in.", "order": 0, "title": "Keyspace", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with Scylla.", "order": 2, "title": "Password", "type": "string" }, "port": { "default": 9042, "description": "Port of Scylla.", "maximum": 65536, "minimum": 0, "order": 4, "title": "Port", "type": "integer" }, "replication": { "default": 1, "description": "Indicates to how many nodes the data should be replicated to.", "order": 5, "title": "Replication factor", "type": "integer" }, "username": { "description": "Username to use to access Scylla.", "order": 1, "title": "Username", "type": "string" } }, "required": [ "keyspace", "username", "password", "address", "port", "destination" ], "title": "Scylla", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "cluster_name": { "description": "clusterName of SelectDB", "order": 2, "title": "ClusterName", "type": "string" }, "database": { "description": "Name of the database.", "order": 5, "title": "DataBase Name", "type": "string" }, "destination": { "const": "airbyte-destination-selectdb", "type": "string" }, "jdbc_url": { "description": "jdbc host and port: xxx.privatelink.aliyun.com:30523", "order": 1, "title": "jdbcURL", "type": "string" }, "load_url": { "description": "load host and port: xxx.privatelink.aliyun.com:47057", "order": 0, "title": "loadURL", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "user_name": { "description": "Username to use to access the database.", "order": 3, "title": "UserName", "type": "string" } }, "required": [ "load_url", "jdbc_url", "cluster_name", "user_name", "password", "database", "destination" ], "title": "Selectdb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "destination": { "const": "airbyte-destination-sftp-json", "type": "string" }, "destination_path": { "description": "Path to the directory where json files will be written.", "examples": [ "/json_data" ], "order": 4, "title": "Destination path", "type": "string" }, "host": { "description": "Hostname of the SFTP server.", "order": 0, "title": "Host", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 3, "title": "Password", "type": "string" }, "port": { "default": 22, "description": "Port of the SFTP server.", "examples": [ 22 ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "username": { "description": "Username to use to access the SFTP server.", "order": 2, "title": "User", "type": "string" } }, "required": [ "host", "username", "password", "destination_path", "destination" ], "title": "Sftpjson", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "credentials": { "description": "", "oneOf": [ { "order": 0, "properties": { "access_token": { "instillCredentialField": true, "description": "Enter you application's Access Token", "title": "Access Token", "type": "string" }, "auth_type": { "const": "OAuth2.0", "default": "OAuth2.0", "enum": [ "OAuth2.0" ], "order": 0, "type": "string" }, "client_id": { "instillCredentialField": true, "description": "Enter your application's Client ID", "title": "Client ID", "type": "string" }, "client_secret": { "instillCredentialField": true, "description": "Enter your application's Client secret", "title": "Client Secret", "type": "string" }, "refresh_token": { "instillCredentialField": true, "description": "Enter your application's Refresh Token", "title": "Refresh Token", "type": "string" } }, "required": [ "access_token", "refresh_token" ], "title": "OAuth2.0", "type": "object" }, { "order": 1, "properties": { "auth_type": { "const": "Key Pair Authentication", "default": "Key Pair Authentication", "enum": [ "Key Pair Authentication" ], "order": 0, "type": "string" }, "private_key": { "instillCredentialField": true, "description": "RSA Private key to use for Snowflake connection. See the <a href=\"https://docs.airbyte.com/integrations/destinations/snowflake\">docs</a> for more information on how to obtain this key.", "multiline": true, "title": "Private Key", "type": "string" }, "private_key_password": { "instillCredentialField": true, "description": "Passphrase for private key", "title": "Passphrase", "type": "string" } }, "required": [ "private_key" ], "title": "Key Pair Authentication", "type": "object" }, { "order": 2, "properties": { "auth_type": { "const": "Username and Password", "default": "Username and Password", "enum": [ "Username and Password" ], "order": 0, "type": "string" }, "password": { "instillCredentialField": true, "description": "Enter the password associated with the username.", "order": 1, "title": "Password", "type": "string" } }, "required": [ "password" ], "title": "Username and Password", "type": "object" } ], "order": 6, "title": "Authorization Method", "type": "object" }, "database": { "description": "Enter the name of the <a href=\"https://docs.snowflake.com/en/sql-reference/ddl-database.html#database-schema-share-ddl\">database</a> you want to sync data into", "examples": [ "AIRBYTE_DATABASE" ], "order": 3, "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-snowflake", "type": "string" }, "disable_type_dedupe": { "default": false, "description": "Disable Writing Final Tables. WARNING! The data format in _airbyte_data is likely stable but there are no guarantees that other metadata columns will remain the same in future versions", "order": 11, "title": "Disable Final Tables. (WARNING! Unstable option; Columns in raw table schema might change between versions)", "type": "boolean" }, "host": { "description": "Enter your Snowflake account's <a href=\"https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier\">locator</a> (in the format <account_locator>.<region>.<cloud>.snowflakecomputing.com)", "examples": [ "accountname.us-east-2.aws.snowflakecomputing.com", "accountname.snowflakecomputing.com" ], "order": 0, "pattern": "^(http(s)?:\\/\\/)?([^./?#]+\\.)?([^./?#]+\\.)?([^./?#]+\\.)?([^./?#]+\\.snowflakecomputing\\.com)$", "pattern_descriptor": "{account_name}.snowflakecomputing.com or {accountname}.{aws_location}.aws.snowflakecomputing.com", "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Enter the additional properties to pass to the JDBC URL string when connecting to the database (formatted as key=value pairs separated by the symbol &). Example: key1=value1&key2=value2&key3=value3", "order": 7, "title": "JDBC URL Params", "type": "string" }, "raw_data_schema": { "description": "The schema to write raw tables into (default: airbyte_internal)", "order": 10, "title": "Raw Table Schema Name", "type": "string" }, "role": { "description": "Enter the <a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#roles\">role</a> that you want to use to access Snowflake", "examples": [ "AIRBYTE_ROLE" ], "order": 1, "title": "Role", "type": "string" }, "schema": { "description": "Enter the name of the default <a href=\"https://docs.snowflake.com/en/sql-reference/ddl-database.html#database-schema-share-ddl\">schema</a>", "examples": [ "AIRBYTE_SCHEMA" ], "order": 4, "title": "Default Schema", "type": "string" }, "username": { "description": "Enter the name of the user you want to use to access the database", "examples": [ "AIRBYTE_USER" ], "order": 5, "title": "Username", "type": "string" }, "warehouse": { "description": "Enter the name of the <a href=\"https://docs.snowflake.com/en/user-guide/warehouses-overview.html#overview-of-warehouses\">warehouse</a> that you want to sync data into", "examples": [ "AIRBYTE_WAREHOUSE" ], "order": 2, "title": "Warehouse", "type": "string" } }, "required": [ "host", "role", "warehouse", "database", "schema", "username", "destination" ], "title": "Snowflake", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "destination": { "const": "airbyte-destination-sqlite", "type": "string" }, "destination_path": { "description": "Path to the sqlite.db file. The file will be placed inside that local mount. For more information check out our <a href=\"https://docs.airbyte.io/integrations/destinations/sqlite\">docs</a>", "example": "/local/sqlite.db", "type": "string" } }, "required": [ "destination_path", "destination" ], "title": "Sqlite", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "properties": { "accept_terms": { "default": false, "description": "You must agree to the Starburst Galaxy <a href=\"https://www.starburst.io/terms/\">terms & conditions</a> to use this connector.", "order": 1, "title": "Agree to the Starburst Galaxy terms & conditions", "type": "boolean" }, "catalog": { "description": "Name of the Starburst Galaxy Amazon S3 catalog.", "examples": [ "sample_s3_catalog" ], "order": 6, "title": "Amazon S3 catalog", "type": "string" }, "catalog_schema": { "default": "public", "description": "The default Starburst Galaxy Amazon S3 catalog schema where tables are written to if the source does not specify a namespace. Defaults to \"public\".", "examples": [ "public" ], "order": 7, "title": "Amazon S3 catalog schema", "type": "string" }, "destination": { "const": "airbyte-destination-starburst-galaxy", "type": "string" }, "password": { "instillCredentialField": true, "description": "Starburst Galaxy password for the specified user.", "examples": [ "password" ], "order": 5, "title": "Password", "type": "string" }, "port": { "default": "443", "description": "Starburst Galaxy cluster port.", "examples": [ "443" ], "order": 3, "title": "Port", "type": "string" }, "purge_staging_table": { "default": true, "description": "Defaults to 'true'. Switch to 'false' for debugging purposes.", "order": 9, "title": "Purge staging Iceberg table", "type": "boolean" }, "server_hostname": { "description": "Starburst Galaxy cluster hostname.", "examples": [ "abc-12345678-wxyz.trino.galaxy-demo.io" ], "order": 2, "title": "Hostname", "type": "string" }, "staging_object_store": { "description": "Temporary storage on which temporary Iceberg table is created.", "oneOf": [ { "properties": { "object_store_type": { "default": "S3", "enum": [ "S3" ], "order": 1, "type": "string" }, "s3_access_key_id": { "instillCredentialField": true, "description": "Access key with access to the bucket. Airbyte requires read and write permissions to a given bucket.", "examples": [ "A012345678910EXAMPLE" ], "order": 4, "title": "Access key", "type": "string" }, "s3_bucket_name": { "description": "Name of the S3 bucket", "examples": [ "airbyte_staging" ], "order": 1, "title": "S3 bucket name", "type": "string" }, "s3_bucket_path": { "description": "Directory in the S3 bucket where staging data is stored.", "examples": [ "temp_airbyte__sync/test" ], "order": 2, "title": "S3 bucket path", "type": "string" }, "s3_bucket_region": { "default": "us-east-1", "description": "The region of the S3 bucket.", "enum": [ "ap-northeast-1", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "eu-central-1", "eu-west-1", "eu-west-2", "eu-west-3", "us-east-1", "us-east-2", "us-west-1", "us-west-2" ], "order": 3, "title": "S3 bucket region", "type": "string" }, "s3_secret_access_key": { "instillCredentialField": true, "description": "Secret key used with the specified access key.", "examples": [ "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY" ], "order": 5, "title": "Secret key", "type": "string" } }, "required": [ "object_store_type", "s3_bucket_name", "s3_bucket_path", "s3_bucket_region", "s3_access_key_id", "s3_secret_access_key" ], "title": "Amazon S3" } ], "order": 8, "title": "Staging object store", "type": "object" }, "username": { "description": "Starburst Galaxy user.", "examples": [ "user@example.com" ], "order": 4, "title": "User", "type": "string" } }, "required": [ "accept_terms", "server_hostname", "username", "password", "catalog", "staging_object_store", "destination" ], "title": "Starburstgalaxy", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "destination": { "const": "airbyte-destination-teradata", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 7, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 2, "title": "Password", "type": "string" }, "schema": { "default": "airbyte_td", "description": "The default schema tables are written to if the source does not specify a namespace. The usual value for this field is \"public\".", "examples": [ "airbyte_td" ], "order": 3, "title": "Default Schema", "type": "string" }, "ssl": { "default": false, "description": "Encrypt data using SSL. When activating SSL, please select one of the connection modes.", "order": 5, "title": "SSL Connection", "type": "boolean" }, "ssl_mode": { "description": "SSL connection modes. \n <b>disable</b> - Chose this mode to disable encryption of communication between Airbyte and destination database\n <b>allow</b> - Chose this mode to enable encryption only when required by the destination database\n <b>prefer</b> - Chose this mode to allow unencrypted connection only if the destination database does not support encryption\n <b>require</b> - Chose this mode to always require encryption. If the destination database server does not support encryption, connection will fail\n <b>verify-ca</b> - Chose this mode to always require encryption and to verify that the destination database server has a valid SSL certificate\n <b>verify-full</b> - This is the most secure mode. Chose this mode to always require encryption and to verify the identity of the destination database server\n See more information - <a href=\"https://teradata-docs.s3.amazonaws.com/doc/connectivity/jdbc/reference/current/jdbcug_chapter_2.html#URL_SSLMODE\"> in the docs</a>.", "oneOf": [ { "additionalProperties": false, "description": "Disable SSL.", "properties": { "mode": { "const": "disable", "default": "disable", "enum": [ "disable" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "disable" }, { "additionalProperties": false, "description": "Allow SSL mode.", "properties": { "mode": { "const": "allow", "default": "allow", "enum": [ "allow" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "allow" }, { "additionalProperties": false, "description": "Prefer SSL mode.", "properties": { "mode": { "const": "prefer", "default": "prefer", "enum": [ "prefer" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "prefer" }, { "additionalProperties": false, "description": "Require SSL mode.", "properties": { "mode": { "const": "require", "default": "require", "enum": [ "require" ], "order": 0, "type": "string" } }, "required": [ "mode" ], "title": "require" }, { "additionalProperties": false, "description": "Verify-ca SSL mode.", "properties": { "mode": { "const": "verify-ca", "default": "verify-ca", "enum": [ "verify-ca" ], "order": 0, "type": "string" }, "ssl_ca_certificate": { "instillCredentialField": true, "description": "Specifies the file name of a PEM file that contains Certificate Authority (CA) certificates for use with SSLMODE=verify-ca.\n See more information - <a href=\"https://teradata-docs.s3.amazonaws.com/doc/connectivity/jdbc/reference/current/jdbcug_chapter_2.html#URL_SSLCA\"> in the docs</a>.", "multiline": true, "order": 1, "title": "CA certificate", "type": "string" } }, "required": [ "mode", "ssl_ca_certificate" ], "title": "verify-ca" }, { "additionalProperties": false, "description": "Verify-full SSL mode.", "properties": { "mode": { "const": "verify-full", "default": "verify-full", "enum": [ "verify-full" ], "order": 0, "type": "string" }, "ssl_ca_certificate": { "instillCredentialField": true, "description": "Specifies the file name of a PEM file that contains Certificate Authority (CA) certificates for use with SSLMODE=verify-full.\n See more information - <a href=\"https://teradata-docs.s3.amazonaws.com/doc/connectivity/jdbc/reference/current/jdbcug_chapter_2.html#URL_SSLCA\"> in the docs</a>.", "multiline": true, "order": 1, "title": "CA certificate", "type": "string" } }, "required": [ "mode", "ssl_ca_certificate" ], "title": "verify-full" } ], "order": 6, "title": "SSL modes", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 1, "title": "User", "type": "string" } }, "required": [ "host", "username", "destination" ], "title": "Teradata", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-tidb", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "default": "", "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 4000, "description": "Port of the database.", "examples": [ "4000" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "ssl": { "default": false, "description": "Encrypt data using SSL.", "order": 5, "title": "SSL Connection", "type": "boolean" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "database", "destination" ], "title": "Tidb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "apikey": { "instillCredentialField": true, "description": "Personal API key", "order": 1, "title": "API key", "type": "string" }, "destination": { "const": "airbyte-destination-timeplus", "type": "string" }, "endpoint": { "default": "https://us.timeplus.cloud/<workspace_id>", "description": "Timeplus workspace endpoint", "examples": [ "https://us.timeplus.cloud/workspace_id" ], "order": 0, "title": "Endpoint", "type": "string" } }, "required": [ "endpoint", "apikey", "destination" ], "title": "Timeplus", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "api_key": { "description": "Typesense API Key", "order": 0, "title": "API Key", "type": "string" }, "batch_size": { "description": "How many documents should be imported together. Default 1000", "order": 4, "title": "Batch size", "type": "integer" }, "destination": { "const": "airbyte-destination-typesense", "type": "string" }, "host": { "description": "Hostname of the Typesense instance without protocol.", "order": 1, "title": "Host", "type": "string" }, "port": { "description": "Port of the Typesense instance. Ex: 8108, 80, 443. Default is 443", "order": 2, "title": "Port", "type": "string" }, "protocol": { "description": "Protocol of the Typesense instance. Ex: http or https. Default is https", "order": 3, "title": "Protocol", "type": "string" } }, "required": [ "api_key", "host", "destination" ], "title": "Typesense", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "DB Name", "type": "string" }, "destination": { "const": "airbyte-destination-vertica", "type": "string" }, "host": { "description": "Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password associated with the username.", "order": 4, "title": "Password", "type": "string" }, "port": { "default": 5433, "description": "Port of the database.", "examples": [ "5433" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "description": "Schema for vertica destination", "order": 7, "title": "Schema", "type": "string" }, "tunnel_method": { "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.", "oneOf": [ { "properties": { "tunnel_method": { "const": "NO_TUNNEL", "description": "No ssh tunnel needed to connect to database", "order": 0, "type": "string" } }, "required": [ "tunnel_method" ], "title": "No Tunnel" }, { "properties": { "ssh_key": { "instillCredentialField": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "multiline": true, "order": 4, "title": "SSH Private Key", "type": "string" }, "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_KEY_AUTH", "description": "Connect through a jump server tunnel host using username and ssh key", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host.", "order": 3, "title": "SSH Login Username", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key" ], "title": "SSH Key Authentication" }, { "properties": { "tunnel_host": { "description": "Hostname of the jump server host that allows inbound ssh tunnel.", "order": 1, "title": "SSH Tunnel Jump Server Host", "type": "string" }, "tunnel_method": { "const": "SSH_PASSWORD_AUTH", "description": "Connect through a jump server tunnel host using username and password authentication", "order": 0, "type": "string" }, "tunnel_port": { "default": 22, "description": "Port on the proxy/jump server that accepts inbound ssh connections.", "examples": [ "22" ], "maximum": 65536, "minimum": 0, "order": 2, "title": "SSH Connection Port", "type": "integer" }, "tunnel_user": { "description": "OS-level username for logging into the jump server host", "order": 3, "title": "SSH Login Username", "type": "string" }, "tunnel_user_password": { "instillCredentialField": true, "description": "OS-level password for logging into the jump server host", "order": 4, "title": "Password", "type": "string" } }, "required": [ "tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password" ], "title": "Password Authentication" } ], "title": "SSH Tunnel Method", "type": "object" }, "username": { "description": "Username to use to access the database.", "order": 3, "title": "User", "type": "string" } }, "required": [ "host", "port", "username", "database", "schema", "destination" ], "title": "Vertica", "type": "object" }, { "description": "The configuration model for the Vector DB based destinations. This model is used to generate the UI for the destination configuration,\nas well as to provide type safety for the configuration passed to the destination.\n\nThe configuration model is composed of four parts:\n* Processing configuration\n* Embedding configuration\n* Indexing configuration\n* Advanced configuration\n\nProcessing, embedding and advanced configuration are provided by this base class, while the indexing configuration is provided by the destination connector in the sub class.", "groups": [ { "id": "processing", "title": "Processing" }, { "id": "embedding", "title": "Embedding" }, { "id": "indexing", "title": "Indexing" }, { "id": "advanced", "title": "Advanced" } ], "properties": { "destination": { "const": "airbyte-destination-weaviate", "type": "string" }, "embedding": { "description": "Embedding configuration", "group": "embedding", "oneOf": [ { "description": "Do not calculate and pass embeddings to Weaviate. Suitable for clusters with configured vectorizers to calculate embeddings within Weaviate or for classes that should only support regular text search.", "properties": { "mode": { "const": "no_embedding", "default": "no_embedding", "enum": [ "no_embedding" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "No external embedding", "type": "object" }, { "description": "Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "api_base": { "description": "The base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "https://your-resource-name.openai.azure.com" ], "title": "Resource base URL", "type": "string" }, "deployment": { "description": "The deployment for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "examples": [ "your-resource-name" ], "title": "Deployment", "type": "string" }, "mode": { "const": "azure_openai", "default": "azure_openai", "enum": [ "azure_openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "description": "The API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource", "title": "Azure OpenAI API key", "type": "string" } }, "required": [ "openai_key", "api_base", "deployment", "mode" ], "title": "Azure OpenAI", "type": "object" }, { "description": "Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions.", "properties": { "mode": { "const": "openai", "default": "openai", "enum": [ "openai" ], "title": "Mode", "type": "string" }, "openai_key": { "instillCredentialField": true, "title": "OpenAI API key", "type": "string" } }, "required": [ "openai_key", "mode" ], "title": "OpenAI", "type": "object" }, { "description": "Use the Cohere API to embed text.", "properties": { "cohere_key": { "instillCredentialField": true, "title": "Cohere API key", "type": "string" }, "mode": { "const": "cohere", "default": "cohere", "enum": [ "cohere" ], "title": "Mode", "type": "string" } }, "required": [ "cohere_key", "mode" ], "title": "Cohere", "type": "object" }, { "description": "Use a field in the record as the embedding. This is useful if you already have an embedding for your data and want to store it in the vector store.", "properties": { "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "field_name": { "description": "Name of the field in the record that contains the embedding", "examples": [ "embedding", "vector" ], "title": "Field name", "type": "string" }, "mode": { "const": "from_field", "default": "from_field", "enum": [ "from_field" ], "title": "Mode", "type": "string" } }, "required": [ "field_name", "dimensions", "mode" ], "title": "From Field", "type": "object" }, { "description": "Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs.", "properties": { "mode": { "const": "fake", "default": "fake", "enum": [ "fake" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "Fake", "type": "object" }, { "description": "Use a service that's compatible with the OpenAI API to embed text.", "properties": { "api_key": { "instillCredentialField": true, "default": "", "title": "API key", "type": "string" }, "base_url": { "description": "The base URL for your OpenAI-compatible service", "examples": [ "https://your-service-name.com" ], "title": "Base URL", "type": "string" }, "dimensions": { "description": "The number of dimensions the embedding model is generating", "examples": [ 1536, 384 ], "title": "Embedding dimensions", "type": "integer" }, "mode": { "const": "openai_compatible", "default": "openai_compatible", "enum": [ "openai_compatible" ], "title": "Mode", "type": "string" }, "model_name": { "default": "text-embedding-ada-002", "description": "The name of the model to use for embedding", "examples": [ "text-embedding-ada-002" ], "title": "Model name", "type": "string" } }, "required": [ "base_url", "dimensions", "mode" ], "title": "OpenAI-compatible", "type": "object" } ], "title": "Embedding", "type": "object" }, "indexing": { "description": "Indexing configuration", "group": "indexing", "properties": { "additional_headers": { "default": [], "description": "Additional HTTP headers to send with every request.", "examples": [ { "header_key": "X-OpenAI-Api-Key", "value": "my-openai-api-key" } ], "items": { "properties": { "header_key": { "title": "Header Key", "type": "string" }, "value": { "instillCredentialField": true, "title": "Header Value", "type": "string" } }, "required": [ "header_key", "value" ], "title": "Header", "type": "object" }, "title": "Additional headers", "type": "array" }, "auth": { "description": "Authentication method", "oneOf": [ { "description": "Authenticate using an API token (suitable for Weaviate Cloud)", "properties": { "mode": { "const": "token", "default": "token", "enum": [ "token" ], "title": "Mode", "type": "string" }, "token": { "instillCredentialField": true, "description": "API Token for the Weaviate instance", "title": "API Token", "type": "string" } }, "required": [ "token", "mode" ], "title": "API Token", "type": "object" }, { "description": "Authenticate using username and password (suitable for self-managed Weaviate clusters)", "properties": { "mode": { "const": "username_password", "default": "username_password", "enum": [ "username_password" ], "title": "Mode", "type": "string" }, "password": { "instillCredentialField": true, "description": "Password for the Weaviate cluster", "order": 2, "title": "Password", "type": "string" }, "username": { "description": "Username for the Weaviate cluster", "order": 1, "title": "Username", "type": "string" } }, "required": [ "username", "password", "mode" ], "title": "Username/Password", "type": "object" }, { "description": "Do not authenticate (suitable for locally running test clusters, do not use for clusters with public IP addresses)", "properties": { "mode": { "const": "no_auth", "default": "no_auth", "enum": [ "no_auth" ], "title": "Mode", "type": "string" } }, "required": [ "mode" ], "title": "No Authentication", "type": "object" } ], "order": 2, "title": "Authentication", "type": "object" }, "batch_size": { "default": 128, "description": "The number of records to send to Weaviate in each batch", "title": "Batch Size", "type": "integer" }, "default_vectorizer": { "default": "none", "description": "The vectorizer to use if new classes need to be created", "enum": [ "none", "text2vec-cohere", "text2vec-huggingface", "text2vec-openai", "text2vec-palm", "text2vec-contextionary", "text2vec-transformers", "text2vec-gpt4all" ], "title": "Default Vectorizer", "type": "string" }, "host": { "description": "The public endpoint of the Weaviate cluster.", "examples": [ "https://my-cluster.weaviate.network" ], "order": 1, "title": "Public Endpoint", "type": "string" }, "text_field": { "default": "text", "description": "The field in the object that contains the embedded text", "title": "Text Field", "type": "string" } }, "required": [ "host", "auth" ], "title": "Indexing", "type": "object" }, "omit_raw_text": { "default": false, "description": "Do not store the text that gets embedded along with the vector and the metadata in the destination. If set to true, only the vector and the metadata will be stored - in this case raw text for LLM use cases needs to be retrieved from another source.", "group": "advanced", "title": "Do not store raw text", "type": "boolean" }, "processing": { "group": "processing", "properties": { "chunk_overlap": { "default": 0, "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context", "title": "Chunk overlap", "type": "integer" }, "chunk_size": { "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)", "maximum": 8191, "minimum": 1, "title": "Chunk size", "type": "integer" }, "field_name_mappings": { "default": [], "description": "List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation.", "items": { "properties": { "from_field": { "description": "The field name in the source", "title": "From field name", "type": "string" }, "to_field": { "description": "The field name to use in the destination", "title": "To field name", "type": "string" } }, "required": [ "from_field", "to_field" ], "title": "FieldNameMappingConfigModel", "type": "object" }, "title": "Field name mappings", "type": "array" }, "metadata_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path.", "examples": [ "age", "user", "user.name" ], "items": { "type": "string" }, "title": "Fields to store as metadata", "type": "array" }, "text_fields": { "always_show": true, "default": [], "description": "List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.", "examples": [ "text", "user.name", "users.*.name" ], "items": { "type": "string" }, "title": "Text fields to embed", "type": "array" }, "text_splitter": { "description": "Split text fields into chunks based on the specified method.", "oneOf": [ { "description": "Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc.", "properties": { "keep_separator": { "default": false, "description": "Whether to keep the separator in the resulting chunks", "title": "Keep separator", "type": "boolean" }, "mode": { "const": "separator", "default": "separator", "enum": [ "separator" ], "title": "Mode", "type": "string" }, "separators": { "default": [ "\"\\n\\n\"", "\"\\n\"", "\" \"", "\"\"" ], "description": "List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \".\". To split by a newline, use \"\\n\".", "items": { "type": "string" }, "title": "Separators", "type": "array" } }, "required": [ "mode" ], "title": "By Separator", "type": "object" }, { "description": "Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk.", "properties": { "mode": { "const": "markdown", "default": "markdown", "enum": [ "markdown" ], "title": "Mode", "type": "string" }, "split_level": { "default": 1, "description": "Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points", "maximum": 6, "minimum": 1, "title": "Split level", "type": "integer" } }, "required": [ "mode" ], "title": "By Markdown header", "type": "object" }, { "description": "Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks.", "properties": { "language": { "description": "Split code in suitable places based on the programming language", "enum": [ "cpp", "go", "java", "js", "php", "proto", "python", "rst", "ruby", "rust", "scala", "swift", "markdown", "latex", "html", "sol" ], "title": "Language", "type": "string" }, "mode": { "const": "code", "default": "code", "enum": [ "code" ], "title": "Mode", "type": "string" } }, "required": [ "language", "mode" ], "title": "By Programming Language", "type": "object" } ], "title": "Text splitter", "type": "object" } }, "required": [ "chunk_size" ], "title": "ProcessingConfigModel", "type": "object" } }, "required": [ "embedding", "processing", "indexing", "destination" ], "title": "Weaviate", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "api_key": { "instillCredentialField": true, "description": "API Key to connect.", "order": 0, "title": "API Key", "type": "string" }, "db_url": { "description": "URL pointing to your workspace.", "example": "https://my-workspace-abc123.us-east-1.xata.sh/db/nyc-taxi-fares:main", "order": 1, "title": "Database URL", "type": "string" }, "destination": { "const": "airbyte-destination-xata", "type": "string" } }, "required": [ "api_key", "db_url", "destination" ], "title": "Xata", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": true, "properties": { "database": { "description": "Name of the database.", "order": 2, "title": "Database", "type": "string" }, "destination": { "const": "airbyte-destination-yugabytedb", "type": "string" }, "host": { "description": "The Hostname of the database.", "order": 0, "title": "Host", "type": "string" }, "jdbc_url_params": { "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).", "order": 6, "title": "JDBC URL Params", "type": "string" }, "password": { "instillCredentialField": true, "description": "The Password associated with the username.", "order": 5, "title": "Password", "type": "string" }, "port": { "default": 3306, "description": "The Port of the database.", "examples": [ "3306" ], "maximum": 65536, "minimum": 0, "order": 1, "title": "Port", "type": "integer" }, "schema": { "default": "public", "description": "The default schema tables are written to if the source does not specify a namespace. The usual value for this field is \"public\".", "examples": [ "public" ], "order": 3, "title": "Default Schema", "type": "string" }, "username": { "description": "The Username which is used to access the database.", "order": 4, "title": "Username", "type": "string" } }, "required": [ "host", "port", "username", "database", "schema", "destination" ], "title": "Yugabytedb", "type": "object" }, { "$schema": "http://json-schema.org/draft-07/schema#", "additionalProperties": false, "properties": { "destination": { "const": "airbyte-devmate-cloud", "type": "string" }, "privateKey": { "instillCredentialField": true, "description": "You private key on Streamr", "type": "string" }, "streamId": { "description": "Your full Stream ID", "examples": [ "0x0d0102474519cd2fc1b3e3f962a87e39cbcbead2/test-streamr" ], "type": "string" } }, "required": [ "privateKey", "streamId", "destination" ], "title": "Airbytedevmatecloud", "type": "object" } ], "title": "Destination", "type": "object" }
