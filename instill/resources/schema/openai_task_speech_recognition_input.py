# generated by datamodel-codegen:
#   filename:  openai_task_speech_recognition_input.json

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum
from typing import Any, List, Optional


class Model(Enum):
    whisper_1 = 'whisper-1'


@dataclass
class ImageUrl:
    url: str


class Type(Enum):
    text = 'text'
    image_url = 'image_url'


@dataclass
class MultiModalContentItem:
    type: Type
    image_url: Optional[ImageUrl] = None
    text: Optional[str] = None


InstillTypes = Any


@dataclass
class Input:
    audio: bytes
    model: Model
    language: Optional[str] = None
    prompt: Optional[str] = None
    temperature: Optional[float] = None


@dataclass
class ChatMessage:
    content: List[MultiModalContentItem]
    role: str
